# Phase 3: The Guide - Implementation Steps

## Overview

This document provides a detailed 24-week implementation plan for Phase 3: The Guide. The implementation is divided into three major components: Causal Inference Foundation (Weeks 1-8), Conversational Interface (Weeks 9-16), and Goal-Oriented Analysis (Weeks 17-24).

## Implementation Structure

### Month 10-11: Causal Inference Foundation (Weeks 1-8)

#### Week 1-2: Causal Discovery Algorithms Implementation

**Week 1: Setup and Basic Causal Discovery**
- **Day 1-2**: Environment setup and causal inference libraries installation
```bash
# Install causal inference dependencies
pip install causallearn dowhy pgmpy econml lingam
pip install networkx scikit-learn statsmodels

# Setup development environment
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

- **Day 3-4**: Implement basic PC algorithm
```python
# causal_discovery/pc_algorithm.py
import numpy as np
import pandas as pd
from itertools import combinations
from scipy.stats import pearsonr, chi2_contingency
import networkx as nx

class PCAlgorithm:
    def __init__(self, alpha=0.05):
        self.alpha = alpha
        self.graph = None
        self.sep_set = {}

    def fit(self, data: pd.DataFrame) -> nx.DiGraph:
        """Run PC algorithm on input data"""
        # Create complete graph
        nodes = data.columns.tolist()
        self.graph = nx.Graph()
        self.graph.add_nodes_from(nodes)
        self.graph.add_edges_from(combinations(nodes, 2))

        # Phase 1: Adjacency search
        self._adjacency_search(data)

        # Phase 2: Edge orientation
        self._orient_edges()

        return self.graph

    def _adjacency_search(self, data: pd.DataFrame):
        """Adjacency search phase"""
        nodes = list(self.graph.nodes())
        l = 0  # Adjacency set size

        while True:
            edges_to_remove = []

            for (X, Y) in self.graph.edges():
                # Get adjacency sets
                adj_X = set(self.graph.neighbors(X)) - {Y}
                adj_Y = set(self.graph.neighbors(Y)) - {X}

                # Check for separating set of size l
                for S in combinations(adj_X & adj_Y, l):
                    if self._independent(X, Y, list(S), data):
                        edges_to_remove.append((X, Y))
                        self.sep_set[(X, Y)] = set(S)
                        break

            # Remove edges
            for X, Y in edges_to_remove:
                self.graph.remove_edge(X, Y)

            if not edges_to_remove or l >= len(nodes) - 2:
                break

            l += 1

    def _independent(self, X: str, Y: str, S: List[str], data: pd.DataFrame) -> bool:
        """Test conditional independence"""
        if len(S) == 0:
            # Marginal independence
            corr, p_value = pearsonr(data[X], data[Y])
            return p_value > self.alpha
        else:
            # Conditional independence (partial correlation)
            from statsmodels.stats.correlation_tools import partial_corr
            try:
                partial_corr_result = partial_corr(data, x=X, y=Y, zcovar=S)
                return partial_corr_result['p-val'].values[0] > self.alpha
            except:
                return False

    def _orient_edges(self):
        """Orient edges using conditional independence tests"""
        # Rule 1: Orient v-structures
        for (X, Y) in list(self.graph.edges()):
            for Z in set(self.graph.nodes()) - {X, Y}:
                if (not self.graph.has_edge(X, Z) and
                    not self.graph.has_edge(Y, Z) and
                    Z not in self.sep_set.get((X, Y), set())):
                    # Found v-structure X -> Z <- Y
                    if self.graph.has_edge(X, Y):
                        self.graph.remove_edge(X, Y)
                        self.graph.add_edge(X, Z, directed=True)
                        self.graph.add_edge(Y, Z, directed=True)
                    elif self.graph.has_edge(Y, X):
                        self.graph.remove_edge(Y, X)
                        self.graph.add_edge(Y, Z, directed=True)
                        self.graph.add_edge(X, Z, directed=True)

        # Apply Meek rules for further orientation
        self._apply_meek_rules()

    def _apply_meek_rules(self):
        """Apply Meek's orientation rules"""
        changed = True
        while changed:
            changed = False

            # Rule 1: If X -> Y -> Z and X-Z, then orient X -> Z
            for X, Y in self.graph.edges(data=True):
                if Y.get('directed'):
                    for Z in self.graph.neighbors(Y):
                        if self.graph.has_edge(X, Z) and not self.graph.edges[X, Z].get('directed'):
                            self.graph.edges[X, Z]['directed'] = True
                            changed = True

            # Rule 2: If X -> Y <- Z and Y-W, X-W, then orient Y -> W
            # (Implementation of additional Meek rules...)
```

- **Day 5**: Testing and validation
```python
# tests/test_pc_algorithm.py
import pytest
import pandas as pd
import numpy as np
from causal_discovery.pc_algorithm import PCAlgorithm

class TestPCAlgorithm:
    @pytest.fixture
    def linear_data(self):
        """Generate linear causal data"""
        np.random.seed(42)
        n = 1000
        X = np.random.normal(0, 1, n)
        Y = 2 * X + np.random.normal(0, 0.1, n)
        Z = 0.5 * Y + np.random.normal(0, 0.1, n)

        return pd.DataFrame({'X': X, 'Y': Y, 'Z': Z})

    def test_pc_algorithm_linear(self, linear_data):
        """Test PC algorithm on linear data"""
        pc = PCAlgorithm(alpha=0.05)
        graph = pc.fit(linear_data)

        assert len(graph.nodes()) == 3
        assert len(graph.edges()) >= 1

    def test_conditional_independence(self, linear_data):
        """Test conditional independence calculation"""
        pc = PCAlgorithm()
        # X and Z should be independent given Y
        assert pc._independent('X', 'Z', ['Y'], linear_data)
```

**Week 2: Advanced Causal Discovery Methods**
- **Day 1-2**: Implement GES algorithm
- **Day 3-4**: Implement LiNGAM algorithm
- **Day 5**: Ensemble causal discovery

#### Week 3-4: Counterfactual Analysis Engine

**Week 3: Counterfactual Implementation**
```python
# counterfactual/counterfactual_engine.py
import numpy as np
import pandas as pd
from typing import Dict, Any, List
from dataclasses import dataclass
from causallearn.utils.GraphUtils import GraphUtils

@dataclass
class Intervention:
    variable: str
    value: float
    type: str  # 'value', 'do', 'atomic'

@dataclass
class CounterfactualResult:
    intervention: Intervention
    predicted_outcome: float
    confidence: float
    explanation: str
    alternative_scenarios: List[Dict[str, Any]]

class CounterfactualEngine:
    def __init__(self, causal_model, structural_equations):
        self.causal_model = causal_model
        self.structural_equations = structural_equations
        self.simulation_runner = SimulationRunner()

    async def analyze_counterfactual(self,
                                  intervention: Intervention,
                                  context: Dict[str, Any]) -> CounterfactualResult:
        """Analyze counterfactual query"""

        # Run Monte Carlo simulation
        simulation_results = await self.simulation_runner.run_counterfactual(
            self.causal_model,
            intervention,
            n_simulations=1000
        )

        # Calculate statistics
        predicted_outcome = np.mean(simulation_results)
        confidence = self._calculate_confidence_interval(simulation_results)

        # Generate explanation
        explanation = await self._generate_explanation(
            intervention,
            predicted_outcome,
            confidence,
            context
        )

        # Generate alternative scenarios
        alternatives = await self._generate_alternatives(intervention)

        return CounterfactualResult(
            intervention=intervention,
            predicted_outcome=predicted_outcome,
            confidence=confidence,
            explanation=explanation,
            alternative_scenarios=alternatives
        )

    def _calculate_confidence_interval(self, results: np.ndarray) -> float:
        """Calculate 95% confidence interval"""
        lower = np.percentile(results, 2.5)
        upper = np.percentile(results, 97.5)
        return (upper - lower) / 2

    async def _generate_explanation(self,
                                  intervention: Intervention,
                                  outcome: float,
                                  confidence: float,
                                  context: Dict[str, Any]) -> str:
        """Generate natural language explanation"""

        # Get baseline (current state)
        baseline = context.get('current_value', 0)

        # Calculate change
        change = outcome - baseline
        percent_change = (change / baseline) * 100 if baseline != 0 else 0

        # Generate explanation based on change magnitude
        if abs(percent_change) < 5:
            magnitude = "minimal"
        elif abs(percent_change) < 20:
            magnitude = "moderate"
        else:
            magnitude = "significant"

        direction = "increase" if change > 0 else "decrease"

        explanation = f"""
        Setting {intervention.variable} to {intervention.value} would likely lead to a {magnitude} {direction}
        of approximately {abs(change):.2f} units ({abs(percent_change):.1f}%).
        This prediction has a 95% confidence interval of Â±{confidence:.2f}.
        """

        return explanation.strip()
```

**Week 4: Intervention Simulation**
```python
# counterfactual/simulation_runner.py
import numpy as np
import pandas as pd
from typing import List, Dict, Any
from concurrent.futures import ThreadPoolExecutor
import asyncio

class SimulationRunner:
    def __init__(self, n_workers=4):
        self.n_workers = n_workers

    async def run_counterfactual(self,
                               causal_model,
                               intervention: Intervention,
                               n_simulations: int = 1000) -> np.ndarray:
        """Run counterfactual simulations"""

        # Create simulation batches
        batch_size = n_simulations // self.n_workers
        batches = [batch_size] * self.n_workers
        batches[0] += n_simulations % self.n_workers

        # Run simulations in parallel
        with ThreadPoolExecutor(max_workers=self.n_workers) as executor:
            loop = asyncio.get_event_loop()
            tasks = [
                loop.run_in_executor(
                    executor,
                    self._run_batch,
                    causal_model,
                    intervention,
                    batch_size
                )
                for batch_size in batches
            ]

            results = await asyncio.gather(*tasks)

        # Combine results
        return np.concatenate(results)

    def _run_batch(self,
                  causal_model,
                  intervention: Intervention,
                  n_simulations: int) -> np.ndarray:
        """Run a batch of simulations"""

        results = []

        for _ in range(n_simulations):
            # Sample from noise distributions
            noise_samples = self._sample_noise(causal_model)

            # Apply intervention
            modified_model = self._apply_intervention(causal_model, intervention)

            # Run simulation
            outcome = self._simulate_structural_equations(
                modified_model,
                noise_samples
            )

            results.append(outcome)

        return np.array(results)

    def _sample_noise(self, causal_model) -> Dict[str, float]:
        """Sample noise terms for structural equations"""
        noise = {}
        for variable in causal_model.variables:
            # Assume Gaussian noise with estimated variance
            variance = causal_model.get_noise_variance(variable)
            noise[variable] = np.random.normal(0, np.sqrt(variance))
        return noise

    def _apply_intervention(self, causal_model, intervention: Intervention):
        """Apply intervention to causal model"""
        # Create copy of model
        modified_model = causal_model.copy()

        # Set intervention value
        if intervention.type == 'do':
            modified_model.set_variable_value(intervention.variable, intervention.value)
        elif intervention.type == 'atomic':
            modified_model.set_atomic_intervention(intervention.variable, intervention.value)

        return modified_model
```

#### Week 5-6: Causal Graph Visualization

**Week 5: React Flow Integration**
```typescript
// components/CausalGraphVisualization.tsx
import React, { useCallback, useMemo } from 'react';
import ReactFlow, {
  Node,
  Edge,
  addEdge,
  useNodesState,
  useEdgesState,
  Connection,
  Background,
  Controls,
  MiniMap
} from 'reactflow-renderer';
import { CausalNode, CausalEdge, CausalGraph } from '../types/causal';
import { Box, Flex, useColorModeValue } from '@chakra-ui/react';
import 'reactflow-renderer/dist/styles.css';
import CausalNodeComponent from './CausalNode';
import CausalEdgeComponent from './CausalEdge';

interface CausalGraphVisualizationProps {
  graph: CausalGraph;
  onNodeClick?: (node: CausalNode) => void;
  onEdgeClick?: (edge: CausalEdge) => void;
  onIntervention?: (node: CausalNode, value: number) => void;
}

const CausalGraphVisualization: React.FC<CausalGraphVisualizationProps> = ({
  graph,
  onNodeClick,
  onEdgeClick,
  onIntervention
}) => {
  const [nodes, setNodes, onNodesChange] = useNodesState([]);
  const [edges, setEdges, onEdgesChange] = useEdgesState([]);

  // Transform causal graph to ReactFlow format
  const flowData = useMemo(() => {
    const transformedNodes: Node[] = graph.nodes.map((node, index) => ({
      id: node.id,
      position: {
        x: (index % 4) * 200,
        y: Math.floor(index / 4) * 150
      },
      data: {
        node,
        onNodeClick,
        onIntervention
      },
      type: 'causal'
    }));

    const transformedEdges: Edge[] = graph.edges.map((edge, index) => ({
      id: edge.id,
      source: edge.source,
      target: edge.target,
      data: { edge, onEdgeClick },
      type: 'causal',
      animated: edge.causalType === 'direct',
      style: {
        stroke: `rgba(59, 130, 246, ${edge.strength})`,
        strokeWidth: Math.max(1, edge.strength * 5)
      },
      label: `${edge.causalType} (${(edge.confidence * 100).toFixed(0)}%)`
    }));

    return { nodes: transformedNodes, edges: transformedEdges };
  }, [graph]);

  // Update ReactFlow state
  React.useEffect(() => {
    setNodes(flowData.nodes);
    setEdges(flowData.edges);
  }, [flowData]);

  const onConnect = useCallback(
    (params: Edge | Connection) => setEdges((eds) => addEdge(params, eds)),
    [setEdges]
  );

  return (
    <Box width="100%" height="600px" position="relative">
      <ReactFlow
        nodes={nodes}
        edges={edges}
        onNodesChange={onNodesChange}
        onEdgesChange={onEdgesChange}
        onConnect={onConnect}
        nodeTypes={{ causal: CausalNodeComponent }}
        edgeTypes={{ causal: CausalEdgeComponent }}
        fitView
      >
        <Background />
        <Controls />
        <MiniMap />
      </ReactFlow>
    </Box>
  );
};

export default CausalGraphVisualization;
```

**Week 6: Interactive Causal Controls**
```typescript
// components/CausalControls.tsx
import React, { useState } from 'react';
import { Button, ButtonGroup, HStack, Box, Text, useToast } from '@chakra-ui/react';
import { FaMagic, FaUndo, FaRandom, FaQuestionCircle } from 'react-icons/fa';

interface CausalControlsProps {
  onInterventionMode: () => void;
  onResetLayout: () => void;
  onRandomize: () => void;
  onHelp: () => void;
  interventionMode: boolean;
}

const CausalControls: React.FC<CausalControlsProps> = ({
  onInterventionMode,
  onResetLayout,
  onRandomize,
  onHelp,
  interventionMode
}) => {
  const toast = useToast();

  const handleInterventionMode = () => {
    onInterventionMode();
    toast({
      title: interventionMode ? 'Intervention Mode Disabled' : 'Intervention Mode Enabled',
      description: interventionMode
        ? 'Click on nodes to select them'
        : 'Click on nodes to set intervention values',
      status: 'info',
      duration: 2000,
    });
  };

  return (
    <Box
      position="absolute"
      top={4}
      right={4}
      bg="white"
      p={4}
      borderRadius="md"
      boxShadow="lg"
      zIndex={1000}
    >
      <VStack spacing={3}>
        <Text fontWeight="bold" fontSize="sm">
          Causal Graph Controls
        </Text>

        <ButtonGroup isAttached size="sm">
          <Button
            leftIcon={<FaMagic />}
            colorScheme={interventionMode ? 'blue' : 'gray'}
            onClick={handleInterventionMode}
            variant={interventionMode ? 'solid' : 'outline'}
          >
            Intervention Mode
          </Button>

          <Button
            leftIcon={<FaUndo />}
            onClick={onResetLayout}
            variant="outline"
          >
            Reset Layout
          </Button>

          <Button
            leftIcon={<FaRandom />}
            onClick={onRandomize}
            variant="outline"
          >
            Randomize
          </Button>

          <Button
            leftIcon={<FaQuestionCircle />}
            onClick={onHelp}
            variant="outline"
          >
            Help
          </Button>
        </ButtonGroup>

        {interventionMode && (
          <Box
            bg="blue.50"
            p={3}
            borderRadius="md"
            width="100%"
          >
            <Text fontSize="xs" color="blue.800">
              <strong>Intervention Mode Active</strong>
              <br />
              Click on any node to set an intervention value and see predicted effects.
            </Text>
          </Box>
        )}
      </VStack>
    </Box>
  );
};
```

#### Week 7-8: Intervention Simulation Framework

**Week 7: Backend API Implementation**
```python
# api/intervention_api.py
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import Dict, Any, List
import asyncio

from counterfactual.counterfactual_engine import CounterfactualEngine, Intervention

router = APIRouter()

class InterventionRequest(BaseModel):
    variable: str
    value: float
    type: str = "value"
    context: Dict[str, Any] = {}

class InterventionResponse(BaseModel):
    predicted_outcome: float
    confidence: float
    explanation: str
    alternative_scenarios: List[Dict[str, Any]]

# Initialize counterfactual engine
counterfactual_engine = CounterfactualEngine()

@router.post("/intervention/analyze", response_model=InterventionResponse)
async def analyze_intervention(request: InterventionRequest):
    """Analyze intervention effects"""
    try:
        intervention = Intervention(
            variable=request.variable,
            value=request.value,
            type=request.type
        )

        result = await counterfactual_engine.analyze_counterfactual(
            intervention,
            request.context
        )

        return InterventionResponse(
            predicted_outcome=result.predicted_outcome,
            confidence=result.confidence,
            explanation=result.explanation,
            alternative_scenarios=result.alternative_scenarios
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/intervention/batch")
async def batch_intervention_analysis(requests: List[InterventionRequest]):
    """Analyze multiple interventions"""
    try:
        tasks = [
            analyze_intervention(req) for req in requests
        ]
        results = await asyncio.gather(*tasks)
        return {"results": results}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/intervention/suggest/{variable}")
async def suggest_interventions(variable: str, context: Dict[str, Any] = {}):
    """Suggest possible interventions for a variable"""
    try:
        # Get current value and range
        current_value = context.get('current_value', 0)
        variable_range = context.get('range', {'min': -1, 'max': 1})

        # Generate suggested interventions
        suggestions = []

        # Suggest increase/decrease by 10%
        suggestions.append({
            'description': f'Increase {variable} by 10%',
            'intervention': {
                'variable': variable,
                'value': current_value * 1.1,
                'type': 'value'
            }
        })

        suggestions.append({
            'description': f'Decrease {variable} by 10%',
            'intervention': {
                'variable': variable,
                'value': current_value * 0.9,
                'type': 'value'
            }
        })

        # Suggest min/max values
        suggestions.append({
            'description': f'Set {variable} to maximum',
            'intervention': {
                'variable': variable,
                'value': variable_range['max'],
                'type': 'value'
            }
        })

        suggestions.append({
            'description': f'Set {variable} to minimum',
            'intervention': {
                'variable': variable,
                'value': variable_range['min'],
                'type': 'value'
            }
        })

        return {"suggestions": suggestions}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

**Week 8: Testing and Integration**
```python
# tests/test_intervention_system.py
import pytest
import asyncio
from counterfactual.counterfactual_engine import CounterfactualEngine, Intervention

class TestInterventionSystem:
    @pytest.fixture
    def counterfactual_engine(self):
        return CounterfactualEngine()

    @pytest.mark.asyncio
    async def test_simple_intervention(self, counterfactual_engine):
        """Test simple intervention analysis"""
        intervention = Intervention(
            variable='X',
            value=1.0,
            type='value'
        )

        context = {
            'current_value': 0.0,
            'range': {'min': -1, 'max': 1}
        }

        result = await counterfactual_engine.analyze_counterfactual(
            intervention,
            context
        )

        assert result.predicted_outcome is not None
        assert result.confidence > 0
        assert len(result.explanation) > 0
        assert len(result.alternative_scenarios) > 0

    @pytest.mark.asyncio
    async def test_batch_interventions(self, counterfactual_engine):
        """Test batch intervention analysis"""
        interventions = [
            Intervention('X', 0.5),
            Intervention('X', -0.5),
            Intervention('Y', 1.0)
        ]

        tasks = [
            counterfactual_engine.analyze_counterfactual(
                intervention,
                {}
            )
            for intervention in interventions
        ]

        results = await asyncio.gather(*tasks)

        assert len(results) == 3
        for result in results:
            assert result.predicted_outcome is not None
```

### Month 12-13: Conversational Interface (Weeks 9-16)

#### Week 9-10: Natural Language Understanding

**Week 9: Intent Recognition**
```python
# nlp/intent_recognition.py
import spacy
from typing import Dict, Any, List
from transformers import pipeline
import re

class CausalIntentRecognizer:
    def __init__(self):
        self.nlp = spacy.load("en_core_web_lg")
        self.classifier = pipeline("zero-shot-classification",
                                 model="facebook/bart-large-mnli")

        # Define causal intent categories
        self.intent_categories = [
            "causal_discovery",
            "counterfactual_query",
            "intervention_planning",
            "relationship_inquiry",
            "prediction_request",
            "explanation_request",
            "goal_setting",
            "progress_inquiry"
        ]

        # Pattern matching for specific causal phrases
        self.causal_patterns = {
            "causal_discovery": [
                r"what causes",
                r"why does",
                r"what is the relationship between",
                r"how are.*related",
                r"what factors influence"
            ],
            "counterfactual_query": [
                r"what if",
                r"what would happen if",
                r"if i.*then what",
                r"suppose.*what",
                r"what happens when"
            ],
            "intervention_planning": [
                r"how can i",
                r"what should i do to",
                r"how to improve",
                r"what changes.*make",
                r"how to affect"
            ]
        }

    async def recognize_intent(self, text: str) -> Dict[str, Any]:
        """Recognize user intent from text"""

        # Use zero-shot classification
        classification_result = self.classifier(
            text,
            self.intent_categories,
            multi_label=False
        )

        # Get primary intent
        primary_intent = classification_result['labels'][0]
        confidence = classification_result['scores'][0]

        # Check for pattern matches
        pattern_matches = self._check_pattern_matches(text)

        # Extract entities
        doc = self.nlp(text)
        entities = self._extract_entities(doc)

        # Extract temporal context
        temporal_context = self._extract_temporal_context(doc)

        return {
            'intent': primary_intent,
            'confidence': confidence,
            'pattern_matches': pattern_matches,
            'entities': entities,
            'temporal_context': temporal_context,
            'original_text': text
        }

    def _check_pattern_matches(self, text: str) -> Dict[str, List[str]]:
        """Check for pattern matches in text"""
        matches = {}

        for intent_type, patterns in self.causal_patterns.items():
            matches[intent_type] = []
            for pattern in patterns:
                if re.search(pattern, text, re.IGNORECASE):
                    matches[intent_type].append(pattern)

        return matches

    def _extract_entities(self, doc) -> List[Dict[str, Any]]:
        """Extract relevant entities from text"""
        entities = []

        for ent in doc.ents:
            if ent.label_ in ['PERSON', 'ORG', 'GPE', 'PRODUCT', 'EVENT']:
                entities.append({
                    'text': ent.text,
                    'label': ent.label_,
                    'start': ent.start_char,
                    'end': ent.end_char
                })

        # Extract custom causal entities
        causal_entities = self._extract_causal_entities(doc)
        entities.extend(causal_entities)

        return entities

    def _extract_causal_entities(self, doc) -> List[Dict[str, Any]]:
        """Extract causal-specific entities"""
        entities = []

        # Look for causal indicators
        causal_tokens = [
            token for token in doc
            if token.dep_ in ['nsubj', 'dobj'] and token.head.pos_ == 'VERB'
        ]

        for token in causal_tokens:
            entities.append({
                'text': token.text,
                'label': 'CAUSAL_ENTITY',
                'start': token.idx,
                'end': token.idx + len(token.text),
                'dependency': token.dep_,
                'head': token.head.text
            })

        return entities

    def _extract_temporal_context(self, doc) -> Dict[str, Any]:
        """Extract temporal information from text"""
        temporal_entities = [ent for ent in doc.ents if ent.label_ in ['DATE', 'TIME']]

        # Identify temporal indicators
        temporal_indicators = {
            'past': ['yesterday', 'last week', 'previous', 'before'],
            'present': ['now', 'currently', 'today', 'right now'],
            'future': ['tomorrow', 'next week', 'will', 'going to']
        }

        detected_timeframe = []
        text_lower = doc.text.lower()

        for timeframe, indicators in temporal_indicators.items():
            if any(indicator in text_lower for indicator in indicators):
                detected_timeframe.append(timeframe)

        return {
            'entities': temporal_entities,
            'timeframe': detected_timeframe,
            'has_temporal_context': len(temporal_entities) > 0 or len(detected_timeframe) > 0
        }
```

**Week 10: Entity Extraction and Context Understanding**
```python
# nlp/entity_extraction.py
import spacy
from typing import Dict, Any, List, Optional
import re
from dataclasses import dataclass

@dataclass
class CausalEntity:
    text: str
    label: str
    start_pos: int
    end_pos: int
    confidence: float
    metadata: Dict[str, Any]

class CausalEntityExtractor:
    def __init__(self):
        self.nlp = spacy.load("en_core_web_lg")
        self.causal_verbs = [
            'cause', 'lead to', 'result in', 'influence', 'affect', 'impact',
            'change', 'alter', 'modify', 'increase', 'decrease', 'improve'
        ]
        self.modality_words = ['would', 'could', 'should', 'might', 'may']

    async def extract_entities(self, text: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """Extract entities and relationships from text"""

        doc = self.nlp(text)

        # Extract standard entities
        standard_entities = self._extract_standard_entities(doc)

        # Extract causal entities
        causal_entities = self._extract_causal_entities(doc)

        # Extract relationships
        relationships = self._extract_relationships(doc)

        # Extract modality and certainty
        modality = self._extract_modality(doc)

        # Extract quantities and measurements
        quantities = self._extract_quantities(doc)

        return {
            'standard_entities': standard_entities,
            'causal_entities': causal_entities,
            'relationships': relationships,
            'modality': modality,
            'quantities': quantities,
            'context': context or {}
        }

    def _extract_standard_entities(self, doc) -> List[CausalEntity]:
        """Extract standard named entities"""
        entities = []

        for ent in doc.ents:
            entity = CausalEntity(
                text=ent.text,
                label=ent.label_,
                start_pos=ent.start_char,
                end_pos=ent.end_char,
                confidence=0.9,  # spaCy doesn't provide confidence by default
                metadata={'dependency': ent.root.dep_, 'head': ent.root.head.text}
            )
            entities.append(entity)

        return entities

    def _extract_causal_entities(self, doc) -> List[CausalEntity]:
        """Extract causal-specific entities"""
        entities = []

        # Find causal relationships in dependency tree
        for token in doc:
            if token.lemma_ in self.causal_verbs:
                # Extract subject and object
                subject = self._find_subject(token)
                object_ = self._find_object(token)

                if subject and object_:
                    # Create causal relationship entities
                    subject_entity = CausalEntity(
                        text=subject.text,
                        label='CAUSE',
                        start_pos=subject.idx,
                        end_pos=subject.idx + len(subject.text),
                        confidence=0.8,
                        metadata={'verb': token.text, 'relation': 'causes'}
                    )

                    object_entity = CausalEntity(
                        text=object_.text,
                        label='EFFECT',
                        start_pos=object_.idx,
                        end_pos=object_.idx + len(object_.text),
                        confidence=0.8,
                        metadata={'verb': token.text, 'relation': 'caused_by'}
                    )

                    entities.extend([subject_entity, object_entity])

        return entities

    def _find_subject(self, token) -> Optional[Any]:
        """Find subject of a verb"""
        for child in token.children:
            if child.dep_ in ['nsubj', 'nsubjpass']:
                return child
        return None

    def _find_object(self, token) -> Optional[Any]:
        """Find object of a verb"""
        for child in token.children:
            if child.dep_ in ['dobj', 'pobj', 'attr']:
                return child
        return None

    def _extract_relationships(self, doc) -> List[Dict[str, Any]]:
        """Extract relationships between entities"""
        relationships = []

        for token in doc:
            if token.pos_ == 'VERB':
                subject = self._find_subject(token)
                object_ = self._find_object(token)

                if subject and object_:
                    relationship = {
                        'subject': subject.text,
                        'verb': token.text,
                        'object': object_.text,
                        'type': 'action',
                        'confidence': 0.7
                    }
                    relationships.append(relationship)

        return relationships

    def _extract_modality(self, doc) -> Dict[str, Any]:
        """Extract modality and certainty information"""
        modal_tokens = [token for token in doc if token.lower_ in self.modality_words]

        # Check for certainty indicators
        certainty_indicators = {
            'certain': ['definitely', 'certainly', 'surely', 'without doubt'],
            'probable': ['probably', 'likely', 'probably', 'chances are'],
            'possible': ['possibly', 'maybe', 'perhaps', 'potentially'],
            'uncertain': ['uncertain', 'not sure', 'maybe not', 'possibly not']
        }

        detected_certainty = []
        text_lower = doc.text.lower()

        for certainty_level, indicators in certainty_indicators.items():
            if any(indicator in text_lower for indicator in indicators):
                detected_certainty.append(certainty_level)

        return {
            'modal_tokens': [token.text for token in modal_tokens],
            'certainty_level': detected_certainty[0] if detected_certainty else 'neutral',
            'has_modality': len(modal_tokens) > 0
        }

    def _extract_quantities(self, doc) -> List[Dict[str, Any]]:
        """Extract quantities and measurements"""
        quantities = []

        # Find numerical entities
        for ent in doc.ents:
            if ent.label_ in ['CARDINAL', 'PERCENT', 'MONEY', 'QUANTITY']:
                quantity = {
                    'text': ent.text,
                    'value': self._parse_number(ent.text),
                    'unit': self._extract_unit(ent.text),
                    'type': ent.label_,
                    'start_pos': ent.start_char,
                    'end_pos': ent.end_char
                }
                quantities.append(quantity)

        return quantities

    def _parse_number(self, text: str) -> Optional[float]:
        """Parse number from text"""
        try:
            # Remove non-numeric characters except decimal point and percent
            clean_text = re.sub(r'[^\d.]', '', text.replace('%', ''))
            return float(clean_text)
        except:
            return None

    def _extract_unit(self, text: str) -> Optional[str]:
        """Extract unit from quantity text"""
        # Common units mapping
        unit_patterns = {
            'percent': ['%', 'percent', 'percentage'],
            'dollars': ['$', 'dollar', 'dollars'],
            'time': ['minutes', 'hours', 'days', 'weeks', 'months', 'years']
        }

        text_lower = text.lower()
        for unit, patterns in unit_patterns.items():
            if any(pattern in text_lower for pattern in patterns):
                return unit

        return None
```

#### Week 11-12: Multi-turn Conversation Management

**Week 11: Dialogue State Management**
```python
# conversation/dialogue_manager.py
from typing import Dict, Any, List, Optional
from dataclasses import dataclass, field
from datetime import datetime
import json
from enum import Enum

class DialogueState(Enum):
    GREETING = "greeting"
    CAUSAL_QUERY = "causal_query"
    COUNTERFACTUAL = "counterfactual"
    INTERVENTION = "intervention"
    GOAL_DISCUSSION = "goal_discussion"
    FOLLOW_UP = "follow_up"
    CLOSING = "closing"

@dataclass
class DialogueTurn:
    speaker: str  # "user" or "assistant"
    message: str
    timestamp: datetime
    intent: Optional[str] = None
    entities: List[Dict[str, Any]] = field(default_factory=list)
    context: Dict[str, Any] = field(default_factory=dict)
    response_id: Optional[str] = None

@dataclass
class DialogueContext:
    current_state: DialogueState
    history: List[DialogueTurn] = field(default_factory=list)
    current_topic: Optional[str] = None
    active_variables: List[str] = field(default_factory=list)
    pending_questions: List[str] = field(default_factory=list)
    user_goals: List[Dict[str, Any]] = field(default_factory=list)
    session_metadata: Dict[str, Any] = field(default_factory=dict)

class DialogueStateManager:
    def __init__(self):
        self.contexts = {}  # user_id -> DialogueContext
        self.max_history = 50  # Maximum turns to keep in history

    def create_context(self, user_id: str) -> DialogueContext:
        """Create new dialogue context for user"""
        context = DialogueContext(
            current_state=DialogueState.GREETING,
            session_metadata={
                'created_at': datetime.utcnow(),
                'last_activity': datetime.utcnow()
            }
        )
        self.contexts[user_id] = context
        return context

    def get_context(self, user_id: str) -> Optional[DialogueContext]:
        """Get dialogue context for user"""
        return self.contexts.get(user_id)

    def update_context(self, user_id: str, turn: DialogueTurn) -> DialogueContext:
        """Update dialogue context with new turn"""
        context = self.get_context(user_id)
        if not context:
            context = self.create_context(user_id)

        # Add to history
        context.history.append(turn)

        # Limit history size
        if len(context.history) > self.max_history:
            context.history = context.history[-self.max_history:]

        # Update state based on intent
        if turn.intent:
            context.current_state = self._determine_new_state(turn.intent, context.current_state)

        # Update context metadata
        context.session_metadata['last_activity'] = datetime.utcnow()
        context.session_metadata['total_turns'] = len(context.history)

        return context

    def _determine_new_state(self, intent: str, current_state: DialogueState) -> DialogueState:
        """Determine new dialogue state based on intent"""
        state_transitions = {
            DialogueState.GREETING: {
                'causal_discovery': DialogueState.CAUSAL_QUERY,
                'counterfactual_query': DialogueState.COUNTERFACTUAL,
                'intervention_planning': DialogueState.INTERVENTION,
                'goal_setting': DialogueState.GOAL_DISCUSSION
            },
            DialogueState.CAUSAL_QUERY: {
                'follow_up': DialogueState.FOLLOW_UP,
                'counterfactual_query': DialogueState.COUNTERFACTUAL,
                'intervention_planning': DialogueState.INTERVENTION
            },
            DialogueState.COUNTERFACTUAL: {
                'follow_up': DialogueState.FOLLOW_UP,
                'intervention_planning': DialogueState.INTERVENTION
            },
            DialogueState.INTERVENTION: {
                'follow_up': DialogueState.FOLLOW_UP,
                'goal_setting': DialogueState.GOAL_DISCUSSION
            },
            DialogueState.GOAL_DISCUSSION: {
                'follow_up': DialogueState.FOLLOW_UP,
                'causal_discovery': DialogueState.CAUSAL_QUERY
            },
            DialogueState.FOLLOW_UP: {
                'causal_discovery': DialogueState.CAUSAL_QUERY,
                'counterfactual_query': DialogueState.COUNTERFACTUAL,
                'intervention_planning': DialogueState.INTERVENTION,
                'goal_setting': DialogueState.GOAL_DISCUSSION
            }
        }

        # Get possible transitions from current state
        transitions = state_transitions.get(current_state, {})
        return transitions.get(intent, current_state)

    def get_relevant_context(self, user_id: str, max_turns: int = 10) -> Dict[str, Any]:
        """Get relevant context for response generation"""
        context = self.get_context(user_id)
        if not context:
            return {}

        recent_history = context.history[-max_turns:] if context.history else []

        # Extract key information from history
        key_topics = []
        mentioned_variables = set()
        user_goals = []

        for turn in recent_history:
            if turn.entities:
                for entity in turn.entities:
                    if entity.get('label') in ['CAUSE', 'EFFECT', 'VARIABLE']:
                        mentioned_variables.add(entity['text'])
            if turn.intent == 'goal_setting':
                user_goals.extend(turn.context.get('goals', []))
            if turn.current_topic:
                key_topics.append(turn.current_topic)

        return {
            'current_state': context.current_state.value,
            'recent_history': [
                {
                    'speaker': turn.speaker,
                    'message': turn.message,
                    'intent': turn.intent,
                    'timestamp': turn.timestamp.isoformat()
                }
                for turn in recent_history
            ],
            'key_topics': list(set(key_topics)),
            'mentioned_variables': list(mentioned_variables),
            'user_goals': user_goals,
            'session_duration': (datetime.utcnow() - context.session_metadata['created_at']).total_seconds(),
            'total_turns': len(context.history)
        }

    def clear_context(self, user_id: str):
        """Clear dialogue context for user"""
        if user_id in self.contexts:
            del self.contexts[user_id]
```

**Week 12: Response Generation System**
```python
# conversation/response_generator.py
from typing import Dict, Any, List, Optional
import asyncio
from dataclasses import dataclass
from datetime import datetime

@dataclass
class ResponsePlan:
    response_type: str  # 'explanation', 'recommendation', 'question', 'clarification'
    content_template: str
    data: Dict[str, Any]
    confidence: float
    follow_up_suggestions: List[str]

class ResponseGenerator:
    def __init__(self, llm_service, knowledge_graph):
        self.llm_service = llm_service
        self.knowledge_graph = knowledge_graph
        self.templates = self._load_response_templates()

    async def generate_response(self,
                              intent_data: Dict[str, Any],
                              context: Dict[str, Any],
                              analysis_result: Dict[str, Any]) -> str:
        """Generate context-aware response"""

        # Create response plan
        response_plan = await self._create_response_plan(
            intent_data,
            context,
            analysis_result
        )

        # Generate response content
        response_content = await self._generate_content(response_plan)

        # Add personalization
        personalized_response = await self._personalize_response(
            response_content,
            context
        )

        return personalized_response

    async def _create_response_plan(self,
                                  intent_data: Dict[str, Any],
                                  context: Dict[str, Any],
                                  analysis_result: Dict[str, Any]) -> ResponsePlan:
        """Create plan for response generation"""

        intent = intent_data.get('intent', 'general')
        confidence = intent_data.get('confidence', 0.5)

        # Select response type based on intent
        if intent == 'causal_discovery':
            return await self._plan_causal_discovery_response(
                intent_data,
                context,
                analysis_result
            )
        elif intent == 'counterfactual_query':
            return await self._plan_counterfactual_response(
                intent_data,
                context,
                analysis_result
            )
        elif intent == 'intervention_planning':
            return await self._plan_intervention_response(
                intent_data,
                context,
                analysis_result
            )
        elif intent == 'goal_setting':
            return await self._plan_goal_response(
                intent_data,
                context,
                analysis_result
            )
        else:
            return await self._plan_general_response(
                intent_data,
                context,
                analysis_result
            )

    async def _plan_causal_discovery_response(self,
                                            intent_data: Dict[str, Any],
                                            context: Dict[str, Any],
                                            analysis_result: Dict[str, Any]) -> ResponsePlan:
        """Plan response for causal discovery queries"""

        causal_graph = analysis_result.get('causal_graph', {})
        entities = intent_data.get('entities', [])

        if not causal_graph or len(causal_graph.get('nodes', [])) == 0:
            return ResponsePlan(
                response_type='clarification',
                content_template='clarification_need_more_data',
                data={'entities': entities},
                confidence=0.3,
                follow_up_suggestions=[
                    'Could you provide more specific information about the variables you\'re interested in?',
                    'What time period are you focusing on?'
                ]
            )

        # Check if we found significant causal relationships
        significant_edges = [
            edge for edge in causal_graph.get('edges', [])
            if edge.get('strength', 0) > 0.5
        ]

        if significant_edges:
            return ResponsePlan(
                response_type='explanation',
                content_template='causal_relationships_found',
                data={
                    'relationships': significant_edges,
                    'graph_summary': causal_graph
                },
                confidence=0.8,
                follow_up_suggestions=[
                    'Would you like to explore any of these relationships further?',
                    'What if we intervened on one of these factors?'
                ]
            )
        else:
            return ResponsePlan(
                response_type='explanation',
                content_template='weak_or_no_relationships',
                data={'graph_summary': causal_graph},
                confidence=0.6,
                follow_up_suggestions=[
                    'Would you like to look at a different time period?',
                    'Are there other variables we should consider?'
                ]
            )

    async def _generate_content(self, response_plan: ResponsePlan) -> str:
        """Generate response content from plan"""
        template = self.templates.get(response_plan.content_template)

        if not template:
            template = self.templates['default_response']

        # Fill template with data
        content = template.format(**response_plan.data)

        # If using LLM, enhance content
        if response_plan.confidence < 0.7:
            enhanced_content = await self.llm_service.enhance_response(
                content,
                response_plan.data
            )
            content = enhanced_content

        return content

    def _load_response_templates(self) -> Dict[str, str]:
        """Load response templates"""
        return {
            'causal_relationships_found': """
Based on your data, I've identified several important causal relationships:

{relationships_summary}

Key findings:
- {key_finding_1}
- {key_finding_2}

These relationships suggest that changes in one area could significantly impact others.
            """,

            'weak_or_no_relationships': """
I've analyzed the data, but I'm not finding strong causal relationships between the variables you mentioned.

This could mean:
- The relationship might be indirect or mediated by other factors
- We might need more data or a different time period
- There could be other variables we haven't considered

{additional_context}
            """,

            'counterfactual_result': """
Based on the causal model, {intervention_description} would likely lead to:

{predicted_outcome}

This prediction has a confidence level of {confidence}%.

Key factors influencing this prediction:
{factor_1}
{factor_2}
            """,

            'intervention_recommendation': """
To achieve your goal of {goal}, I recommend the following interventions:

{recommendations}

Expected outcomes:
{expected_outcomes}

Would you like me to elaborate on any of these recommendations?
            """,

            'clarification_need_more_data': """
I'd like to help you with your causal analysis, but I need a bit more information.

You mentioned: {user_entities}

Could you clarify:
- What specific outcome are you interested in?
- What time period should I focus on?
- Are there other relevant factors I should consider?
            """,

            'default_response': """
I understand you're asking about {topic}. Based on my analysis:

{analysis_summary}

{follow_up_question}
            """
        }

    async def _personalize_response(self,
                                  response_content: str,
                                  context: Dict[str, Any]) -> str:
        """Personalize response based on user context"""
        user_history = context.get('recent_history', [])
        user_goals = context.get('user_goals', [])
        user_preferences = context.get('preferences', {})

        # Add personalization based on user goals
        if user_goals:
            goal_context = f"\n\nConsidering your goal to {user_goals[0].get('description', 'improve')}, "
            response_content += goal_context

        # Add personalization based on previous interactions
        if user_history:
            previous_topics = [turn.get('current_topic') for turn in user_history[-3:]]
            if previous_topics:
                response_content += f"\n\nBuilding on our previous discussion about {previous_topics[-1]}, "

        # Adjust formality based on user preferences
        formality = user_preferences.get('formality', 'neutral')
        if formality == 'casual':
            response_content = self._make_more_casual(response_content)
        elif formality == 'formal':
            response_content = self._make_more_formal(response_content)

        return response_content

    def _make_more_casual(self, text: str) -> str:
        """Make response more casual"""
        replacements = {
            'Based on the analysis': 'Looking at the data',
            'Therefore': 'So',
            'However': 'But',
            'Additionally': 'Also',
            'Significant': 'Important'
        }

        for formal, casual in replacements.items():
            text = text.replace(formal, casual)

        return text

    def _make_more_formal(self, text: str) -> str:
        """Make response more formal"""
        replacements = {
            'Looking at': 'Examining',
            'So': 'Therefore',
            'But': 'However',
            'Also': 'Additionally',
            'Important': 'Significant'
        }

        for casual, formal in replacements.items():
            text = text.replace(casual, formal)

        return text
```

#### Week 13-16: UI Components and Integration

**Week 13-14: Chat Interface Components**
```typescript
// components/ChatInterface.tsx
import React, { useState, useRef, useEffect } from 'react';
import { Box, VStack, HStack, Input, Button, Text, Avatar, Flex, useColorModeValue } from '@chakra-ui/react';
import { FiSend, FiLoader, FiUser, FiBot } from 'react-icons/fi';
import { motion, AnimatePresence } from 'framer-motion';
import ChatMessage from './ChatMessage';
import TypingIndicator from './TypingIndicator';
import SuggestedActions from './SuggestedActions';

interface ChatMessage {
  id: string;
  type: 'user' | 'assistant';
  content: string;
  timestamp: Date;
  data?: any;
  suggestedActions?: string[];
}

interface ChatInterfaceProps {
  onSendMessage: (message: string) => Promise<string>;
  placeholder?: string;
  welcomeMessage?: string;
  suggestedActions?: string[];
}

const ChatInterface: React.FC<ChatInterfaceProps> = ({
  onSendMessage,
  placeholder = "Ask about causal relationships or interventions...",
  welcomeMessage = "Hello! I'm your causal analysis assistant. How can I help you today?",
  suggestedActions = []
}) => {
  const [messages, setMessages] = useState<ChatMessage[]>([]);
  const [inputValue, setInputValue] = useState('');
  const [isLoading, setIsLoading] = useState(false);
  const messagesEndRef = useRef<HTMLDivElement>(null);

  const bgColor = useColorModeValue('white', 'gray.800');
  const borderColor = useColorModeValue('gray.200', 'gray.600');

  // Initialize with welcome message
  useEffect(() => {
    if (messages.length === 0) {
      setMessages([{
        id: 'welcome',
        type: 'assistant',
        content: welcomeMessage,
        timestamp: new Date(),
        suggestedActions: suggestedActions
      }]);
    }
  }, []);

  // Auto-scroll to bottom
  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  };

  const handleSendMessage = async (content: string) => {
    if (!content.trim() || isLoading) return;

    const userMessage: ChatMessage = {
      id: Date.now().toString(),
      type: 'user',
      content: content.trim(),
      timestamp: new Date()
    };

    setMessages(prev => [...prev, userMessage]);
    setInputValue('');
    setIsLoading(true);

    try {
      const response = await onSendMessage(content);

      const assistantMessage: ChatMessage = {
        id: (Date.now() + 1).toString(),
        type: 'assistant',
        content: response,
        timestamp: new Date()
      };

      setMessages(prev => [...prev, assistantMessage]);
    } catch (error) {
      console.error('Error sending message:', error);
      const errorMessage: ChatMessage = {
        id: (Date.now() + 1).toString(),
        type: 'assistant',
        content: 'I apologize, but I encountered an error processing your request. Please try again.',
        timestamp: new Date()
      };
      setMessages(prev => [...prev, errorMessage]);
    } finally {
      setIsLoading(false);
    }
  };

  const handleKeyPress = (e: React.KeyboardEvent) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleSendMessage(inputValue);
    }
  };

  return (
    <Box
      bg={bgColor}
      border="1px"
      borderColor={borderColor}
      borderRadius="lg"
      h="600px"
      display="flex"
      flexDirection="column"
    >
      {/* Messages Area */}
      <VStack
        flex={1}
        spacing={4}
        p={4}
        overflowY="auto"
        align="stretch"
      >
        <AnimatePresence>
          {messages.map((message) => (
            <motion.div
              key={message.id}
              initial={{ opacity: 0, y: 20 }}
              animate={{ opacity: 1, y: 0 }}
              exit={{ opacity: 0, y: -20 }}
              transition={{ duration: 0.3 }}
            >
              <ChatMessage message={message} />
            </motion.div>
          ))}
        </AnimatePresence>

        {isLoading && (
          <motion.div
            initial={{ opacity: 0 }}
            animate={{ opacity: 1 }}
          >
            <TypingIndicator />
          </motion.div>
        )}
        <div ref={messagesEndRef} />
      </VStack>

      {/* Input Area */}
      <Box
        p={4}
        borderTop="1px"
        borderColor={borderColor}
      >
        <HStack spacing={2}>
          <Input
            value={inputValue}
            onChange={(e) => setInputValue(e.target.value)}
            onKeyPress={handleKeyPress}
            placeholder={placeholder}
            variant="filled"
            disabled={isLoading}
            resize="none"
            rows={1}
          />
          <Button
            onClick={() => handleSendMessage(inputValue)}
            disabled={!inputValue.trim() || isLoading}
            colorScheme="blue"
            isLoading={isLoading}
            size="md"
          >
            <FiSend />
          </Button>
        </HStack>

        {/* Suggested Actions */}
        {messages.length > 0 && messages[messages.length - 1].suggestedActions && (
          <SuggestedActions
            actions={messages[messages.length - 1].suggestedActions!}
            onActionSelect={handleSendMessage}
          />
        )}
      </Box>
    </Box>
  );
};

export default ChatInterface;
```

**Week 15-16: Backend Integration and Testing**

### Month 14-15: Goal-Oriented Analysis (Weeks 17-24)

#### Week 17-18: Aspirational Self Framework

**Week 17: Goal Setting System**
```python
# goals/aspirational_self.py
from typing import Dict, Any, List, Optional
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
import json

class GoalType(Enum):
    QUANTITATIVE = "quantitative"
    QUALITATIVE = "qualitative"
    BINARY = "binary"
    HABIT = "habit"

class GoalStatus(Enum):
    ACTIVE = "active"
    PAUSED = "paused"
    COMPLETED = "completed"
    CANCELLED = "cancelled"

@dataclass
class Goal:
    id: str
    user_id: str
    title: str
    description: str
    goal_type: GoalType
    target_value: Optional[float] = None
    current_value: Optional[float] = None
    unit: Optional[str] = None
    deadline: Optional[datetime] = None
    status: GoalStatus = GoalStatus.ACTIVE
    created_at: datetime = field(default_factory=datetime.utcnow)
    updated_at: datetime = field(default_factory=datetime.utcnow)
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class AspirationalProfile:
    user_id: str
    current_state: Dict[str, Any]
    goals: List[Goal]
    gaps: List[Dict[str, Any]]
    recommendations: List[Dict[str, Any]]
    success_metrics: List[Dict[str, Any]]
    created_at: datetime = field(default_factory=datetime.utcnow)
    updated_at: datetime = field(default_factory=datetime.utcnow)

class AspirationalSelfFramework:
    def __init__(self, knowledge_graph, causal_engine, goal_repository):
        self.knowledge_graph = knowledge_graph
        self.causal_engine = causal_engine
        self.goal_repository = goal_repository
        self.progress_analyzer = ProgressAnalyzer()
        self.recommendation_engine = RecommendationEngine()

    async def create_aspirational_profile(self,
                                        user_id: str,
                                        goals: List[Dict[str, Any]],
                                        current_state: Dict[str, Any]) -> AspirationalProfile:
        """Create comprehensive aspirational profile"""

        # Convert goal dictionaries to Goal objects
        goal_objects = []
        for goal_data in goals:
            goal = Goal(
                id=str(hash(f"{user_id}_{goal_data['title']}_{datetime.utcnow().timestamp()}")),
                user_id=user_id,
                title=goal_data['title'],
                description=goal_data.get('description', ''),
                goal_type=GoalType(goal_data.get('type', 'quantitative')),
                target_value=goal_data.get('target_value'),
                current_value=goal_data.get('current_value', 0),
                unit=goal_data.get('unit'),
                deadline=datetime.fromisoformat(goal_data['deadline']) if goal_data.get('deadline') else None,
                metadata=goal_data.get('metadata', {})
            )
            goal_objects.append(goal)

        # Analyze current state
        state_analysis = await self.analyze_current_state(current_state)

        # Identify gaps between current and desired state
        gaps = await self.identify_gaps(state_analysis, goal_objects)

        # Generate personalized recommendations
        recommendations = await self.recommendation_engine.generate_recommendations(
            user_id,
            gaps,
            goal_objects,
            current_state
        )

        # Create success metrics
        success_metrics = self.create_success_metrics(goal_objects)

        # Save goals to repository
        for goal in goal_objects:
            await self.goal_repository.save_goal(goal)

        return AspirationalProfile(
            user_id=user_id,
            current_state=state_analysis,
            goals=goal_objects,
            gaps=gaps,
            recommendations=recommendations,
            success_metrics=success_metrics
        )

    async def analyze_current_state(self, current_state: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze user's current state across all dimensions"""

        # Get relevant knowledge from graph
        relevant_data = await self.knowledge_graph.query_user_state(
            current_state.get('user_id')
        )

        # Analyze patterns and trends
        patterns = await self.analyze_patterns(relevant_data)

        # Identify strengths and weaknesses
        strengths_weaknesses = await self.identify_strengths_weaknesses(patterns)

        # Calculate baseline metrics
        baseline_metrics = self.calculate_baseline_metrics(relevant_data)

        return {
            'relevant_data': relevant_data,
            'patterns': patterns,
            'strengths_weaknesses': strengths_weaknesses,
            'baseline_metrics': baseline_metrics,
            'analysis_timestamp': datetime.utcnow()
        }

    async def identify_gaps(self,
                           state_analysis: Dict[str, Any],
                           goals: List[Goal]) -> List[Dict[str, Any]]:
        """Identify gaps between current state and goals"""

        gaps = []

        for goal in goals:
            gap_analysis = await self.analyze_goal_gap(goal, state_analysis)

            gaps.append({
                'goal_id': goal.id,
                'goal_title': goal.title,
                'current_value': goal.current_value,
                'target_value': goal.target_value,
                'gap_size': gap_analysis['gap_size'],
                'gap_percentage': gap_analysis['gap_percentage'],
                'time_constraint': gap_analysis['time_constraint'],
                'difficulty_level': gap_analysis['difficulty_level'],
                'contributing_factors': gap_analysis['contributing_factors'],
                'recommended_focus_areas': gap_analysis['recommended_focus_areas']
            })

        return gaps

    async def analyze_goal_gap(self, goal: Goal, state_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze specific goal gap"""

        if goal.goal_type == GoalType.QUANTITATIVE:
            return await self._analyze_quantitative_gap(goal, state_analysis)
        elif goal.goal_type == GoalType.QUALITATIVE:
            return await self._analyze_qualitative_gap(goal, state_analysis)
        elif goal.goal_type == GoalType.BINARY:
            return await self._analyze_binary_gap(goal, state_analysis)
        elif goal.goal_type == GoalType.HABIT:
            return await self._analyze_habit_gap(goal, state_analysis)
        else:
            return {'gap_size': 0, 'gap_percentage': 0}

    async def _analyze_quantitative_gap(self, goal: Goal, state_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze gap for quantitative goals"""

        current = goal.current_value or 0
        target = goal.target_value or 0

        gap_size = target - current
        gap_percentage = (gap_size / target * 100) if target != 0 else 0

        # Analyze time constraint
        time_constraint = self._analyze_time_constraint(goal)

        # Determine difficulty level
        difficulty_level = self._determine_difficulty_level(
            gap_percentage,
            time_constraint,
            goal
        )

        # Identify contributing factors using causal analysis
        contributing_factors = await self.causal_engine.identify_goal_factors(
            goal,
            state_analysis
        )

        # Generate focus area recommendations
        focus_areas = self._generate_focus_areas(contributing_factors, goal)

        return {
            'gap_size': gap_size,
            'gap_percentage': gap_percentage,
            'time_constraint': time_constraint,
            'difficulty_level': difficulty_level,
            'contributing_factors': contributing_factors,
            'recommended_focus_areas': focus_areas
        }

    def create_success_metrics(self, goals: List[Goal]) -> List[Dict[str, Any]]:
        """Create success metrics for goals"""

        metrics = []

        for goal in goals:
            goal_metrics = {
                'goal_id': goal.id,
                'progress_metric': self._create_progress_metric(goal),
                'quality_metric': self._create_quality_metric(goal),
                'consistency_metric': self._create_consistency_metric(goal),
                'satisfaction_metric': self._create_satisfaction_metric(goal)
            }

            metrics.append(goal_metrics)

        return metrics

    def _create_progress_metric(self, goal: Goal) -> Dict[str, Any]:
        """Create progress metric for goal"""
        return {
            'type': 'progress',
            'description': f'Progress towards {goal.title}',
            'unit': goal.unit or 'percentage',
            'target': 100,  # 100% completion
            'measurement_frequency': 'weekly'
        }

    def _create_quality_metric(self, goal: Goal) -> Dict[str, Any]:
        """Create quality metric for goal"""
        return {
            'type': 'quality',
            'description': f'Quality of progress towards {goal.title}',
            'unit': 'rating',
            'target': 4.0,  # 4/5 star rating
            'measurement_frequency': 'bi-weekly'
        }

    def _create_consistency_metric(self, goal: Goal) -> Dict[str, Any]:
        """Create consistency metric for goal"""
        return {
            'type': 'consistency',
            'description': f'Consistency of actions towards {goal.title}',
            'unit': 'percentage',
            'target': 80,  # 80% consistency
            'measurement_frequency': 'daily'
        }

    def _create_satisfaction_metric(self, goal: Goal) -> Dict[str, Any]:
        """Create satisfaction metric for goal"""
        return {
            'type': 'satisfaction',
            'description': f'Personal satisfaction with {goal.title} progress',
            'unit': 'rating',
            'target': 4.0,  # 4/5 satisfaction
            'measurement_frequency': 'weekly'
        }
```

**Week 18: Progress Tracking System**
```python
# goals/progress_tracker.py
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
import numpy as np
from scipy import stats

@dataclass
class ProgressUpdate:
    goal_id: str
    timestamp: datetime
    value: float
    notes: Optional[str] = None
    metadata: Dict[str, Any] = None

@dataclass
class ProgressAnalysis:
    goal_id: str
    current_value: float
    progress_rate: float
    trend_direction: str  # 'improving', 'declining', 'stable'
    trend_strength: float  # 0-1
    predicted_completion_date: Optional[datetime]
    confidence_level: float  # 0-1
    insights: List[str]
    recommendations: List[str]

class ProgressTracker:
    def __init__(self, goal_repository, causal_engine):
        self.goal_repository = goal_repository
        self.causal_engine = causal_engine
        self.progress_analyzer = ProgressAnalyzer()

    async def record_progress(self, update: ProgressUpdate) -> Dict[str, Any]:
        """Record progress update and generate analysis"""

        # Save progress update
        await self.goal_repository.save_progress_update(update)

        # Get goal details
        goal = await self.goal_repository.get_goal(update.goal_id)

        # Get progress history
        history = await self.goal_repository.get_progress_history(update.goal_id)

        # Analyze progress
        analysis = await self.analyze_progress(goal, history, update)

        # Generate insights
        insights = await self.generate_progress_insights(goal, analysis)

        # Update goal if needed
        await self.update_goal_state(goal, analysis)

        return {
            'analysis': analysis,
            'insights': insights,
            'goal_updated': True
        }

    async def analyze_progress(self,
                             goal: Goal,
                             history: List[ProgressUpdate],
                             latest_update: ProgressUpdate) -> ProgressAnalysis:
        """Analyze progress patterns and trends"""

        # Calculate progress rate
        progress_rate = self._calculate_progress_rate(goal, history)

        # Analyze trend
        trend_analysis = self._analyze_trend(history)

        # Predict completion date
        predicted_completion = self._predict_completion_date(
            goal,
            progress_rate,
            trend_analysis
        )

        # Calculate confidence level
        confidence = self._calculate_confidence_level(
            goal,
            history,
            trend_analysis
        )

        # Generate insights
        insights = self._generate_trend_insights(trend_analysis, goal)

        # Generate recommendations
        recommendations = await self._generate_progress_recommendations(
            goal,
            analysis,
            trend_analysis
        )

        return ProgressAnalysis(
            goal_id=goal.id,
            current_value=latest_update.value,
            progress_rate=progress_rate,
            trend_direction=trend_analysis['direction'],
            trend_strength=trend_analysis['strength'],
            predicted_completion_date=predicted_completion,
            confidence_level=confidence,
            insights=insights,
            recommendations=recommendations
        )

    def _calculate_progress_rate(self, goal: Goal, history: List[ProgressUpdate]) -> float:
        """Calculate rate of progress towards goal"""
        if len(history) < 2:
            return 0.0

        # Sort by timestamp
        sorted_history = sorted(history, key=lambda x: x.timestamp)

        # Calculate change over time
        time_span = (sorted_history[-1].timestamp - sorted_history[0].timestamp).total_seconds()
        value_change = sorted_history[-1].value - sorted_history[0].value

        if time_span == 0:
            return 0.0

        # Return progress per day
        return value_change / (time_span / 86400)  # Convert seconds to days

    def _analyze_trend(self, history: List[ProgressUpdate]) -> Dict[str, Any]:
        """Analyze trend in progress data"""
        if len(history) < 3:
            return {'direction': 'stable', 'strength': 0.0}

        # Extract values and timestamps
        values = [update.value for update in history]
        timestamps = [(update.timestamp - history[0].timestamp).total_seconds() / 86400
                     for update in history]

        # Perform linear regression
        slope, intercept, r_value, p_value, std_err = stats.linregress(timestamps, values)

        # Determine trend direction
        if abs(slope) < 0.01:
            direction = 'stable'
        elif slope > 0:
            direction = 'improving'
        else:
            direction = 'declining'

        # Calculate trend strength (0-1)
        strength = min(abs(r_value), 1.0)

        return {
            'direction': direction,
            'strength': strength,
            'slope': slope,
            'r_squared': r_value ** 2,
            'p_value': p_value,
            'confidence': 1 - p_value
        }

    def _predict_completion_date(self,
                               goal: Goal,
                               progress_rate: float,
                               trend_analysis: Dict[str, Any]) -> Optional[datetime]:
        """Predict when goal will be completed"""

        if goal.target_value is None or progress_rate == 0:
            return None

        current_value = goal.current_value or 0
        remaining = goal.target_value - current_value

        if remaining <= 0:
            return datetime.utcnow()  # Already completed

        # Calculate time to completion
        days_to_completion = remaining / progress_rate

        if days_to_completion <= 0:
            return datetime.utcnow()

        # Adjust based on trend confidence
        confidence_adjustment = 1 + (1 - trend_analysis['confidence']) * 0.5
        days_to_completion *= confidence_adjustment

        predicted_date = datetime.utcnow() + timedelta(days=days_to_completion)

        return predicted_date

    async def generate_progress_insights(self,
                                       goal: Goal,
                                       analysis: ProgressAnalysis) -> List[str]:
        """Generate insights from progress analysis"""
        insights = []

        # Trend-based insights
        if analysis.trend_direction == 'improving':
            insights.append(f"Your progress towards {goal.title} is consistently improving.")
        elif analysis.trend_direction == 'declining':
            insights.append(f"Your progress towards {goal.title} has been declining recently.")
        else:
            insights.append(f"Your progress towards {goal.title} has been stable.")

        # Rate-based insights
        if analysis.progress_rate > 0:
            if analysis.predicted_completion_date:
                days_to_completion = (analysis.predicted_completion_date - datetime.utcnow()).days
                if days_to_completion > 0:
                    insights.append(f"At your current rate, you'll reach your goal in approximately {days_to_completion} days.")

        # Confidence-based insights
        if analysis.confidence_level > 0.8:
            insights.append("Your progress patterns show strong consistency.")
        elif analysis.confidence_level < 0.5:
            insights.append("Your progress has been variable, making predictions less certain.")

        return insights

    async def _generate_progress_recommendations(self,
                                                goal: Goal,
                                                analysis: ProgressAnalysis,
                                                trend_analysis: Dict[str, Any]) -> List[str]:
        """Generate recommendations based on progress analysis"""
        recommendations = []

        # Trend-based recommendations
        if trend_analysis['direction'] == 'declining':
            recommendations.append("Consider reassessing your approach or setting smaller milestones.")
        elif trend_analysis['direction'] == 'stable':
            recommendations.append("Try introducing new strategies to accelerate your progress.")

        # Rate-based recommendations
        if analysis.progress_rate < 0.1:
            recommendations.append("Focus on daily actions that contribute to your goal.")
        elif goal.deadline and analysis.predicted_completion_date:
            if analysis.predicted_completion_date > goal.deadline:
                recommendations.append("Increase your daily efforts to meet your deadline.")

        # Consistency recommendations
        if trend_analysis['confidence'] < 0.5:
            recommendations.append("Establish a more consistent routine to improve predictability.")

        return recommendations
```

#### Week 19-20: Personalized Recommendation Engine

**Week 19-20: Adaptive Learning System**
```python
# learning/adaptive_system.py
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
import joblib

@dataclass
class LearningData:
    user_id: str
    context: Dict[str, Any]
    action: str
    outcome: Dict[str, Any]
    feedback: float  # -1 to 1
    timestamp: datetime

@dataclass
class AdaptationResult:
    model_updates: Dict[str, Any]
    preference_updates: Dict[str, Any]
    performance_improvements: Dict[str, float]
    confidence_scores: Dict[str, float]

class AdaptiveLearningSystem:
    def __init__(self):
        self.learning_data = []
        self.user_models = {}  # user_id -> trained model
        self.user_preferences = {}  # user_id -> preference profile
        self.scalers = {}  # user_id -> data scaler
        self.performance_history = {}  # user_id -> performance metrics

    async def learn_from_interaction(self,
                                  interaction_data: Dict[str, Any]) -> AdaptationResult:
        """Learn from user interaction to improve system performance"""

        # Convert to learning data
        learning_data = self._convert_to_learning_data(interaction_data)

        # Store learning data
        self.learning_data.append(learning_data)

        # Update user model
        model_updates = await self._update_user_model(learning_data)

        # Update user preferences
        preference_updates = await self._update_user_preferences(learning_data)

        # Analyze performance improvements
        performance_improvements = self._analyze_performance_improvements(learning_data.user_id)

        # Calculate confidence scores
        confidence_scores = self._calculate_confidence_scores(learning_data.user_id)

        return AdaptationResult(
            model_updates=model_updates,
            preference_updates=preference_updates,
            performance_improvements=performance_improvements,
            confidence_scores=confidence_scores
        )

    async def _update_user_model(self, learning_data: LearningData) -> Dict[str, Any]:
        """Update user's personal model based on new data"""

        user_id = learning_data.user_id
        user_data = self._get_user_learning_data(user_id)

        if len(user_data) < 10:  # Minimum data threshold
            return {'status': 'insufficient_data', 'model_updated': False}

        # Prepare features and labels
        X, y = self._prepare_training_data(user_data)

        # Update or create scaler
        if user_id not in self.scalers:
            self.scalers[user_id] = StandardScaler()

        X_scaled = self.scalers[user_id].fit_transform(X)

        # Update or create model
        if user_id in self.user_models:
            # Retrain existing model
            model = self.user_models[user_id]
            model.fit(X_scaled, y)
        else:
            # Create new model
            model = RandomForestClassifier(n_estimators=100, random_state=42)
            model.fit(X_scaled, y)
            self.user_models[user_id] = model

        # Save model
        self._save_user_model(user_id, model)

        return {
            'status': 'success',
            'model_updated': True,
            'training_samples': len(user_data),
            'feature_importance': dict(zip(X.columns, model.feature_importances_))
        }

    async def _update_user_preferences(self, learning_data: LearningData) -> Dict[str, Any]:
        """Update user preference profile"""

        user_id = learning_data.user_id

        # Initialize preference profile if needed
        if user_id not in self.user_preferences:
            self.user_preferences[user_id] = {
                'response_style': 'balanced',
                'detail_level': 'medium',
                'formality': 'neutral',
                'action_orientation': 'moderate',
                'preferred_topics': [],
                'avoided_topics': [],
                'interaction_patterns': {},
                'feedback_history': []
            }

        preferences = self.user_preferences[user_id]

        # Update preferences based on feedback
        feedback = learning_data.feedback

        # Update response style preference
        if learning_data.action == 'response_generated':
            if feedback > 0.5:
                # Positive feedback, reinforce current style
                preferences['feedback_history'].append({
                    'type': 'response_style',
                    'value': preferences['response_style'],
                    'feedback': feedback,
                    'timestamp': learning_data.timestamp
                })
            else:
                # Negative feedback, consider style adjustment
                pass  # Implement style adjustment logic

        # Update topic preferences
        topics = learning_data.context.get('topics', [])
        for topic in topics:
            if feedback > 0.5:
                if topic not in preferences['preferred_topics']:
                    preferences['preferred_topics'].append(topic)
                if topic in preferences['avoided_topics']:
                    preferences['avoided_topics'].remove(topic)
            elif feedback < -0.5:
                if topic not in preferences['avoided_topics']:
                    preferences['avoided_topics'].append(topic)
                if topic in preferences['preferred_topics']:
                    preferences['preferred_topics'].remove(topic)

        # Update interaction patterns
        interaction_type = learning_data.context.get('interaction_type', 'unknown')
        if interaction_type not in preferences['interaction_patterns']:
            preferences['interaction_patterns'][interaction_type] = []

        preferences['interaction_patterns'][interaction_type].append({
            'feedback': feedback,
            'timestamp': learning_data.timestamp
        })

        # Clean up old feedback history (keep last 1000)
        if len(preferences['feedback_history']) > 1000:
            preferences['feedback_history'] = preferences['feedback_history'][-1000:]

        return {
            'status': 'success',
            'preferences_updated': True,
            'current_preferences': preferences
        }

    def _get_user_learning_data(self, user_id: str) -> List[LearningData]:
        """Get learning data for specific user"""
        return [data for data in self.learning_data if data.user_id == user_id]

    def _prepare_training_data(self, user_data: List[LearningData]):
        """Prepare features and labels for training"""
        # Extract features from learning data
        features = []
        labels = []

        for data in user_data:
            # Create feature vector from context and action
            feature_vector = self._create_feature_vector(data.context, data.action)
            features.append(feature_vector)

            # Use feedback as label (convert to binary: positive/negative)
            label = 1 if data.feedback > 0 else 0
            labels.append(label)

        return pd.DataFrame(features), np.array(labels)

    def _create_feature_vector(self, context: Dict[str, Any], action: str) -> Dict[str, float]:
        """Create feature vector from context and action"""
        features = {}

        # Time-based features
        if 'timestamp' in context:
            hour = context['timestamp'].hour
            features['hour_of_day'] = hour / 24.0
            features['is_weekend'] = 1.0 if context['timestamp'].weekday() >= 5 else 0.0

        # Context features
        features['interaction_type_' + action] = 1.0

        # Topic features
        topics = context.get('topics', [])
        for topic in topics:
            features['topic_' + topic] = 1.0

        # Complexity features
        features['complexity'] = context.get('complexity', 0.5)

        # Sentiment features
        features['sentiment'] = context.get('sentiment', 0.0)

        return features

    def _analyze_performance_improvements(self, user_id: str) -> Dict[str, float]:
        """Analyze performance improvements over time"""
        user_data = self._get_user_learning_data(user_id)

        if len(user_data) < 20:
            return {'insufficient_data': True}

        # Calculate moving average of feedback
        window_size = 10
        moving_averages = []

        for i in range(window_size, len(user_data)):
            window_data = user_data[i-window_size:i]
            avg_feedback = np.mean([d.feedback for d in window_data])
            moving_averages.append(avg_feedback)

        # Calculate trend
        if len(moving_averages) >= 2:
            recent_avg = np.mean(moving_averages[-5:])
            earlier_avg = np.mean(moving_averages[-10:-5])
            improvement = recent_avg - earlier_avg
        else:
            improvement = 0.0

        return {
            'feedback_trend': improvement,
            'recent_performance': np.mean(moving_averages[-5:]) if moving_averages else 0.0,
            'stability': np.std(moving_averages) if moving_averages else 0.0
        }

    def _calculate_confidence_scores(self, user_id: str) -> Dict[str, float]:
        """Calculate confidence scores for different aspects of the system"""
        user_data = self._get_user_learning_data(user_id)

        if len(user_data) < 5:
            return {'overall_confidence': 0.5}

        # Calculate prediction confidence
        if user_id in self.user_models:
            model = self.user_models[user_id]
            recent_data = user_data[-10:] if len(user_data) >= 10 else user_data

            if recent_data:
                X, _ = self._prepare_training_data(recent_data)
                X_scaled = self.scalers[user_id].transform(X)

                # Get prediction probabilities
                if hasattr(model, 'predict_proba'):
                    probabilities = model.predict_proba(X_scaled)
                    confidence_scores = np.max(probabilities, axis=1)
                    prediction_confidence = np.mean(confidence_scores)
                else:
                    prediction_confidence = 0.5
            else:
                prediction_confidence = 0.5
        else:
            prediction_confidence = 0.5

        # Calculate preference confidence
        preferences = self.user_preferences.get(user_id, {})
        feedback_history = preferences.get('feedback_history', [])

        if feedback_history:
            preference_confidence = min(len(feedback_history) / 100.0, 1.0)
        else:
            preference_confidence = 0.5

        # Calculate overall confidence
        overall_confidence = (prediction_confidence + preference_confidence) / 2.0

        return {
            'overall_confidence': overall_confidence,
            'prediction_confidence': prediction_confidence,
            'preference_confidence': preference_confidence
        }

    def _save_user_model(self, user_id: str, model):
        """Save user model to persistent storage"""
        # Implement model persistence
        model_path = f"models/user_{user_id}.pkl"
        joblib.dump(model, model_path)

        scaler_path = f"models/user_{user_id}_scaler.pkl"
        joblib.dump(self.scalers[user_id], scaler_path)
```

#### Week 21-24: UI Components and System Integration

**Week 21-22: Goal Dashboard Components**
```typescript
// components/GoalDashboard.tsx
import React, { useState, useEffect } from 'react';
import { Box, VStack, HStack, Grid, GridItem, Card, CardHeader, CardBody,
         Text, Button, Progress, Stat, StatLabel, StatValue, StatHelpText,
         useColorModeValue, Flex, Badge, Avatar } from '@chakra-ui/react';
import { FiTarget, FiTrendingUp, FiClock, FiCheckCircle, FiAlertCircle, FiPlus } from 'react-icons/fi';
import { motion } from 'framer-motion';
import GoalCard from './GoalCard';
import ProgressChart from './ProgressChart';
import CreateGoalModal from './CreateGoalModal';

interface Goal {
  id: string;
  title: string;
  description: string;
  type: 'quantitative' | 'qualitative' | 'binary' | 'habit';
  targetValue?: number;
  currentValue?: number;
  unit?: string;
  deadline?: string;
  status: 'active' | 'paused' | 'completed' | 'cancelled';
  progress: number;
  trend: 'improving' | 'declining' | 'stable';
  nextMilestone?: string;
}

interface GoalDashboardProps {
  goals: Goal[];
  onCreateGoal: (goal: Omit<Goal, 'id'>) => Promise<void>;
  onUpdateGoal: (goalId: string, updates: Partial<Goal>) => Promise<void>;
  onRecordProgress: (goalId: string, value: number, notes?: string) => Promise<void>;
}

const GoalDashboard: React.FC<GoalDashboardProps> = ({
  goals,
  onCreateGoal,
  onUpdateGoal,
  onRecordProgress
}) => {
  const [isCreateModalOpen, setIsCreateModalOpen] = useState(false);
  const [selectedGoal, setSelectedGoal] = useState<Goal | null>(null);
  const [viewMode, setViewMode] = useState<'grid' | 'list'>('grid');

  const bgColor = useColorModeValue('white', 'gray.800');
  const borderColor = useColorModeValue('gray.200', 'gray.600');

  // Calculate overall statistics
  const activeGoals = goals.filter(goal => goal.status === 'active');
  const completedGoals = goals.filter(goal => goal.status === 'completed');
  const overallProgress = activeGoals.length > 0
    ? activeGoals.reduce((sum, goal) => sum + goal.progress, 0) / activeGoals.length
    : 0;

  const improvingGoals = activeGoals.filter(goal => goal.trend === 'improving').length;
  const decliningGoals = activeGoals.filter(goal => goal.trend === 'declining').length;

  const handleCreateGoal = async (goalData: Omit<Goal, 'id'>) => {
    await onCreateGoal(goalData);
    setIsCreateModalOpen(false);
  };

  const handleRecordProgress = async (goalId: string, value: number, notes?: string) => {
    await onRecordProgress(goalId, value, notes);
  };

  return (
    <Box p={6}>
      {/* Header */}
      <VStack spacing={6} align="stretch">
        <Flex justify="space-between" align="center">
          <VStack align="start" spacing={1}>
            <Text fontSize="2xl" fontWeight="bold">
              Aspirational Self Dashboard
            </Text>
            <Text color="gray.600">
              Track your progress towards personal growth goals
            </Text>
          </VStack>

          <Button
            leftIcon={<FiPlus />}
            colorScheme="blue"
            onClick={() => setIsCreateModalOpen(true)}
          >
            Create Goal
          </Button>
        </Flex>

        {/* Statistics Overview */}
        <Grid templateColumns="repeat(auto-fit, minmax(200px, 1fr))" gap={4}>
          <Card>
            <CardBody>
              <Stat>
                <StatLabel>Active Goals</StatLabel>
                <StatValue fontSize="2xl">{activeGoals.length}</StatValue>
                <StatHelpText>
                  <Flex align="center">
                    <FiTarget />
                    <Text ml={1}>Currently pursuing</Text>
                  </Flex>
                </StatHelpText>
              </Stat>
            </CardBody>
          </Card>

          <Card>
            <CardBody>
              <Stat>
                <StatLabel>Overall Progress</StatLabel>
                <StatValue fontSize="2xl">{overallProgress.toFixed(1)}%</StatValue>
                <Progress value={overallProgress} size="sm" mt={2} />
              </Stat>
            </CardBody>
          </Card>

          <Card>
            <CardBody>
              <Stat>
                <StatLabel>Improving</StatLabel>
                <StatValue fontSize="2xl">{improvingGoals}</StatValue>
                <StatHelpText>
                  <Flex align="center" color="green.500">
                    <FiTrendingUp />
                    <Text ml={1}>On track</Text>
                  </Flex>
                </StatHelpText>
              </Stat>
            </CardBody>
          </Card>

          <Card>
            <CardBody>
              <Stat>
                <StatLabel>Completed</StatLabel>
                <StatValue fontSize="2xl">{completedGoals.length}</StatValue>
                <StatHelpText>
                  <Flex align="center" color="blue.500">
                    <FiCheckCircle />
                    <Text ml={1}>Achieved</Text>
                  </Flex>
                </StatHelpText>
              </Stat>
            </CardBody>
          </Card>
        </Grid>

        {/* Goals Display */}
        {viewMode === 'grid' ? (
          <Grid templateColumns="repeat(auto-fill, minmax(300px, 1fr))" gap={4}>
            {activeGoals.map((goal) => (
              <motion.div
                key={goal.id}
                initial={{ opacity: 0, y: 20 }}
                animate={{ opacity: 1, y: 0 }}
                transition={{ duration: 0.3 }}
              >
                <GoalCard
                  goal={goal}
                  onUpdate={onUpdateGoal}
                  onRecordProgress={handleRecordProgress}
                  onViewDetails={() => setSelectedGoal(goal)}
                />
              </motion.div>
            ))}
          </Grid>
        ) : (
          <VStack spacing={4} align="stretch">
            {activeGoals.map((goal) => (
              <GoalCard
                key={goal.id}
                goal={goal}
                onUpdate={onUpdateGoal}
                onRecordProgress={handleRecordProgress}
                onViewDetails={() => setSelectedGoal(goal)}
                isListView
              />
            ))}
          </VStack>
        )}

        {/* Progress Chart */}
        {activeGoals.length > 0 && (
          <Card>
            <CardHeader>
              <Text fontSize="lg" fontWeight="bold">
                Progress Overview
              </Text>
            </CardHeader>
            <CardBody>
              <ProgressChart goals={activeGoals} />
            </CardBody>
          </Card>
        )}
      </VStack>

      {/* Create Goal Modal */}
      {isCreateModalOpen && (
        <CreateGoalModal
          isOpen={isCreateModalOpen}
          onClose={() => setIsCreateModalOpen(false)}
          onSubmit={handleCreateGoal}
        />
      )}
    </Box>
  );
};

export default GoalDashboard;
```

**Week 23-24: Final Integration and Testing**

## Success Metrics and Milestones

### Key Milestones
1. **Week 8**: Causal inference foundation complete
2. **Week 16**: Conversational interface operational
3. **Week 24**: Goal-oriented analysis system ready

### Testing Requirements
- Unit test coverage >90%
- Integration tests for all components
- Performance benchmarks met
- User acceptance testing complete

### Deployment Readiness
- Documentation complete
- CI/CD pipeline established
- Monitoring systems in place
- Support procedures documented

This 24-week implementation plan provides a comprehensive roadmap for developing Phase 3: The Guide, with detailed technical implementation steps, code examples, and clear milestones for tracking progress.
# 2501.13904v3.pdf

Published as a conference paper at ICLR 2025
PRIVACY-PRESERVING PERSONALIZED
FEDERATED PROMPT LEARNING FOR
MULTIMODAL LARGE LANGUAGE MODELS
Linh Tran1 Wei Sun2 Stacy Patterson1 Ana Milanova1
1Rensselaer Polytechnic Institute 2 IBM Research
ABSTRACT
Multimodal Large Language Models (LLMs) are pivotal in revolutionizing cus-
tomer support and operations by integrating multiple modalities such as text, im-
ages, and audio. Federated Prompt Learning (FPL) is a recently proposed ap-
proach that combines pre-trained multimodal LLMs such as vision-language mod-
els with federated learning to create personalized, privacy-preserving AI systems.
However, balancing the competing goals of personalization, generalization, and
privacy remains a significant challenge. Over-personalization can lead to overfit-
ting, reducing generalizability, while stringent privacy measures, such as differen-
tial privacy, can hinder both personalization and generalization. In this paper, we
propose a Differentially Private Federated Prompt Learning (DP-FPL) approach
to tackle this challenge by leveraging a low-rank factorization scheme to capture
generalization while maintaining a residual term that preserves expressiveness for
personalization. To ensure privacy, we introduce a novel method where we ap-
ply local differential privacy to the two low-rank components of the local prompt,
and global differential privacy to the global prompt. Our approach mitigates the
impact of privacy noise on the model performance while balancing the tradeoff
between personalization and generalization. Extensive experiments demonstrate
the effectiveness of our approach over other benchmarks.
1 I NTRODUCTION
In recent years, there has been rapid advancement in multimodal large language models (LLMs)
that integrate multiple modality information, including text, images, audio, and video, to enhance
the comprehension and generation capabilities. Vision-Language Models (VLMs) such as CLIP
(Radford et al., 2021) are a variant of multimodal LLMs that learn transferable image and text
representations, making them highly effective in applications such as image captioning and visual
search. One proposed setting for deploying VLMs is a Federated Learning framework that allows
multiple organizations or clients to collaboratively train a global model without directly sharing
their local training data. However, fine-tuning pre-trained VLMs in a FL system is time-consuming
and resource-intensive given the massive number of parameters each VLM has. This gives rise to
Federated Prompt Learning (FPL) which only fine-tunes the soft prompt embedding while freezing
the rest of the VLM model parameters in the FL system (Guo et al., 2023b; Cui et al., 2024). In
FPL, each client fine-tunes their customized prompt using their local data and shares the prompt
with a central server for generalization purposes. The clients can distribute their fine-tuned prompts
as prompt providers to public users who wish to perform downstream inference tasks, also known
as the prompt as a service (PaaS) paradigm (Wu et al., 2024; Yao et al., 2024; Huang et al., 2023).
One significant challenge in such distributed systems is the presence of data heterogeneity, i.e., orga-
nizations often have non-identical and non-independent (non-IID) data distributions, which can vary
widely due to factors such as demographics, usage patterns, or device capabilities. To address this,
personalized FL has emerged to tailor models to the unique data characteristics of each client rather
than solely improving a global model. Personalized FL focuses on learning customized models for
each client, reflecting the heterogeneity of their data (He et al., 2020; Dinh et al., 2020). In the
context of personalized FPL, the goal is for each client to learn and utilize personalized prompts that
1
arXiv:2501.13904v3  [cs.LG]  13 Feb 2025Published as a conference paper at ICLR 2025
better align with their specific data and application needs. Nevertheless, over-personalization can
lead to local data overfitting, preventing the model to generalize well on non-training data. Clients
in an FPL framework may opt to distribute their customized prompts post training to public users for
downstream tasks. However, these users may have different types of inputs that the client’s prompt
is not well generalized to, resulting in suboptimal performance. Consequently, it is crucial to achieve
a nuanced balance between personalization and generalization in a heterogeneous FPL system.
In addition to balancing the tradeoff between personalization and generalization, privacy poses an-
other critical concern in FPL, especially in sensitive domains such as finance, law, and healthcare. In
the PaaS framework, the distributed trained prompts are shown to be susceptible to Membership In-
ference Attack (MIA), potentially exposing details about individual clients’ training data (Wu et al.,
2024). To address this issue, one may consider Differential Privacy (DP) (Dwork et al., 2014) which
ensures an adversary cannot reliably detect the presence or absence of a data sample based on the
output information. However, balancing personalization and privacy under data heterogeneity is a
challenging task. The non-IID nature of the data allows clients to better learn their personalized
prompt, but it amplifies the performance degradation caused by DP due to the high data sensitivity,
impairing both personalization and generalization capabilities. Thus, the key question we aim to
address is: How can we effectively balance personalization, generalization, and privacy in a data
heterogeneous FPL system?
To tackle the above question, we proposed a Differentially Private Federated Prompt Learning (DP-
FPL) approach that leverages low-rank factorization and DP as part of the prompt learning process.
In our framework, each client simultaneously learns a global prompt and a local prompt. The global
prompt is shared in a FL manner for generalized knowledge transfer, while the local prompt is
retained at each client site for personalization. Our contributions are threefold.
• We propose a privacy-preserving personalized federated prompt learning approach with
Differential Privacy for multimodal LLMs. We factorize the local prompt into two lower
rank components with an additional residual term. The factorized low-rank components
allow the model to capture broader patterns that are beneficial across different data distri-
butions, aiding the generalization capability of each client. The residual term is crucial for
retaining the expressiveness lost during the factorization process, thereby preserving the
client-specific learning and improving personalization.
• We preserve privacy by utilizing both Global Differential Privacy (GDP) and Local Differ-
ential Privacy (LDP). Unlike conventional methods that apply noise uniformly to the entire
prompt, we judiciously apply LDP to the two low-rank components of the local prompt,
and GDP to the global prompt. Our privacy mechanism mitigates the effect of DP noise on
model performance while preserving the privacy guarantee post training.
• We conduct extensive experiments on widely adopted datasets to evaluate our proposed
method against other benchmarks. The experimental results demonstrate superior per-
formance of our proposed method in balancing personalization and generalization while
mitigating the model degradation caused by DP noise.
2 R ELATED WORK
Personalized Federated Learning. There are several existing approaches that aim to learn per-
sonalized models for clients in FL settings, including clustering (Ghosh et al., 2020; Berlo et al.,
2020; Shahid et al., 2021), regularization (Shoham et al., 2019; Dinh et al., 2020; Li et al., 2020)
and knowledge distillation (Li & Wang, 2019; He et al., 2020; Fang & Ye, 2022). Personalized FL is
most commonly approached as a multi-task learning problem that simultaneously learns two models
for each client: a global model for generalized knowledge and a local model for personalized data.
Existing methods accomplish this by decoupling the model parameters or layers into global and lo-
cal learning components (Arivazhagan et al., 2019; Deng et al., 2020; Zhang et al., 2020; Collins
et al., 2021; Jeong & Hwang, 2022; Zhang et al., 2023). In the existing literature on personalized
FL, private multi-task learning approaches aim to protect training data by retaining personalized
parameters and sharing differentially private generalized parameters. Examples include Jain et al.
(2021), Hu et al. (2021), Bietti et al. (2022), Yang et al. (2023b) and Xu et al. (2024). However, these
methods are designed for full model training and cannot be directly applied to prompt tuning due to
the difference in the parameter space. Sun et al. (2024) incorporates Low-Rank Adaptation with DP
2Published as a conference paper at ICLR 2025
in a standard FL setting, but they do not consider personalization and prompt learning, making their
method not applicable to our setting.
Federated Prompt Learning. Recent advances in personalized FPL have garnered significant at-
tention (Guo et al., 2023a;b; Li et al., 2023; Yang et al., 2023a; Sun et al., 2023; Deng et al., 2024;
Li et al., 2024; Cui et al., 2024). See Table 1 for comparisons. With the exception of Zhao et al.
(2023) which introduces a privacy-preserving FPL method that leverages DP to protect the under-
lying private data, none of the prior literature considers the privacy issue. Many of these works
require modification to the backbone model, which is not relevant to our approach as we want to
protect the personalized prompt, not the model. Zhao et al. (2023) does not account for the crucial
aspects of personalization. Similar to our work, Cui et al. (2024) also factorizes the local prompt
into two learnable low-rank components for balancing personalization and generalization. We in-
stead have the learnable full-rank local prompt, and only keep the low-rank terms non-permanent
for generalization with an additional residual to retain the expressiveness for personalization.
Table 1: Recent Federated Prompt Learning algorithms
FPL Algorithm Consider No model Adopt low-rank Provide privacy
personalization modification factorization guarantee
pFedPrompt (Guo et al., 2023a) ✓ ✗ ✗ ✗
PromptFL(Guo et al., 2023b) ✓ ✓ ✗ ✗
pFedPT (Li et al., 2023) ✓ ✗ ✗ ✗
pFedPG (Yang et al., 2023a) ✓ ✗ ✗ ✗
Fedperfix (Sun et al., 2023) ✓ ✗ ✗ ✗
SGPT (Deng et al., 2024) ✓ ✗ ✗ ✗
FedOTP (Li et al., 2024) ✓ ✓ ✗ ✗
FedPGP (Cui et al., 2024) ✓ ✓ ✓ ✗
Fedprompt (Zhao et al., 2023) ✗ ✓ ✗ ✓
DP-FPL (ours) ✓ ✓ ✓ ✓
3 P ROPOSED METHOD
We introduce our proposed method, Differentially Private Federated Prompt Learning (DP-FPL),
shown in Figure 1. Our approach leverages low-rank factorization with an additional residual term
to balance personalization and generalization in a differentially private FPL system.
3.1 P RELIMINARIES ON PERSONALIZED FEDERATED PROMPT LEARNING
Our system follows a standard FPL setting that consists of a set ofN clients and a central server. Let
the global dataset be D = [D1, D2, . . . , DN ], each client i holds a local subset Di of ni samples.
Each client local model involves a frozen pre-trained VLM such as a CLIP model and a prompt
learner, and their goal is to learn the representation between the visual and prompt information to
improve multimodal classification tasks. Specifically, the frozen CLIP model involves a text encoder
f(·) and an image encoder g(·) that respectively transform the prompt and an image x into text and
image features. The prompt learner trains a soft prompt pi for client i that is optimized to align
with the visual features. Using cos[·, ·] to denote the cosine similarity used by CLIP model, the
classification prediction probability for each client i is computed as:
p(ˆy = j|x) = exp(cos[f(pi, cj), g(x)]/τ)PC
k=1 exp(cos[f(pi, ck), g(x)]/τ)
, (1)
where ˆy denotes the predicted label, cj denotes label j out of C number of classes, and τ denotes the
temperature parameter of CLIP. The client personalized prompt pi is optimized with cross-entropy
loss:
L = − 1
|Di|
X
(x,y)∈Di
CX
j=1
y log p(ˆy = j|x). (2)
3
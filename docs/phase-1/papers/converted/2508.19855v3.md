# 2508.19855v3.pdf

Youtu-GraphRAG
Youtu-GraphRAG: Vertically Unified Agents for Graph
Retrieval-Augmented Complex Reasoning
Junnan Dong1â€ , Siyu An1â€ â€¡ , Yifei Yu1, Qian-Wen Zhang1, Linhao Luo2,
Xiao Huang3, Yunsheng Wu1, Di Yin1,Xing Sun1
1Tencent Youtu Lab
2Monash University
3The Hong Kong Polytechnic University
Graph retrieval-augmented generation (GraphRAG) has effectively enhanced large language models
in complex reasoning by organizing fragmented knowledge into explicitly structured graphs. Prior
efforts have been made to improve either graph construction or graph retrieval in isolation, yielding
suboptimal performance, especially when domain shifts occur. In this paper, we propose a vertically
unified agentic paradigm, Youtu-GraphRAG, to jointly connect the entire framework as an intricate
integration. Specifically, (i) a seed graph schema is introduced to bound the automatic extraction
agent with targeted entity types, relations and attribute types, also continuously expanded for
scalability over unseen domains; (ii) To obtain higher-level knowledge upon the schema, we develop
novel dually-perceived community detection, fusing structural topology with subgraph semantics
for comprehensive knowledge organization. This naturally yields a hierarchical knowledge tree that
supports both top-down filtering and bottom-up reasoning with community summaries; (iii) An
agentic retriever is designed to interpret the same graph schema to transform complex queries into
tractable and parallel sub-queries. It iteratively performs reflection for more advanced reasoning;(iv)
To alleviate the knowledge leaking problem in pre-trained LLM, we propose a tailored anonymous
dataset and a novel â€˜Anonymity Reversionâ€™ task that deeply measures the real performance of the
GraphRAG frameworks. Extensive experiments across six challenging benchmarks demonstrate
the robustness of Youtu-GraphRAG, remarkably moving the Pareto frontier with up to 90.71% saving
of token costs and 16.62% higher accuracy over state-of-the-art baselines. The results indicate our
adaptability, allowing seamless domain transfer with minimal intervention on schema.
Code: https://github.com/TencentCloudADP/Youtu-GraphRAG
Data: https://huggingface.co/datasets/Youtu-Graph/AnonyRAG
1 Introduction
Graph retrieval-augmented generation (GraphRAG) has emerged as a promising paradigm to enhance large
language models (LLMs) with structured knowledge [Xiao et al., 2025, Pan et al., 2024], particularly for
complex multi-hop reasoning tasks across multiple documents[Wang et al., 2024, Zhang et al., 2024]. By
representing fragmented documents as connected graphs with underlying relations [He et al., 2024, Dong
et al., 2023], GraphRAG enables LLMs to traverse explicit paths among documents and entities, performing
complex reasoning that is otherwise infeasible within flat retrieval [Peng et al., 2024, Han et al., 2024]. The
structured approach effectively addresses critical limitations in conventional RAG ([Dong et al., 2024]), which
often struggles with the coherent relations between discrete pieces of information and multi-hop reasoning.
â€  Equal contribution. hansonjdong@tencent.com, siyuan@tencent.com
â€¡ Corresponding author.
1
arXiv:2508.19855v3  [cs.IR]  3 Sep 2025Youtu-GraphRAG
The evolution of GraphRAG brings two distinct but equally important trajectories since the foundational
work of [Edge et al., 2024]. First, from the retrieval front, LightRAG [Guo et al., 2024] pioneered vector
sparsification to improve efficiency. While GNN-RAG and GFM-RAG ([Mavromatis and Karypis, 2024, Luo
et al., 2025]) advanced this direction further by incorporating graph neural networks for fine-grained node
matching, more recent HippoRAG 1&2 [Jimenez Gutierrez et al., 2024, GutiÃ©rrez et al., 2025] introduced
(a)
(b)
(c)
Retrieval
GraphConstruction
LLM
LLM
LLM
GraphConstruction
DocumentsRetrieval
Query
Query
GraphConstructionRetrievalIndexing
Figure 1. A sketched comparison among
existing pipelines and Youtu-GraphRAG.
represents a non-tailored component, indicat-
ing current methods focus on either graph
construction (a) or retrieval (b) in isolation,
while Youtu-GraphRAG proposes a unified
paradigm (c) for superior complex reasoning.
memory and personalized PageRank algorithms for context-
aware retrieval. Second, in terms of graph construction, existing
methods can be broadly categorized into flat and hierarchical
approaches. Early methods, such as KGP [Wang et al., 2024],
rely on existing hyperlinks or KNN-based graphs, resulting in
coarse-grained relations that fail to capture nuanced hierarchical
semantics. More recent advancements, such as GraphRAG [Edge
et al., 2024], combine knowledge graphs with community detec-
tion and summarization for multi-level information. Followed
by hierarchical methods like RAPTOR [Sarthi et al., 2024] and
E2GraphRAG [Zhao et al., 2025], they further refine the graph
using tree-like clustering and recursive summarization to enrich
structural representation. However, they remain constrained by
their isolated optimizations, concentrating on either construction
or retrieval while neglecting their interdependencies. This po-
tentially limits complex reasoning performance where cohesive
knowledge organization and retrieval are equally important.
To bridge this gap, we aim to answer a critical question:
How can we effectively unify graph construction and retrieval
for more robust complex reasoning?
This task is challenging for two reasons. First, construction and retrieval are not readily aligned as two distinct
components. It remains difficult to organically establish synergy between them, where the constructed graph
could effectively benefit retrieval with both structures and semantics. Second, how to properly evaluate the
performance remains a tough problem. With the rapid scaling of LLMs, almost all the existing datasets have
already been â€˜seenâ€™ before. This fails to reflect the real performance of the entire GraphRAG.
In this paper, we propose a vertically unified agentic paradigm,Youtu-GraphRAG, to jointly consider both
graph construction and retrieval as an intricate integration based on graph schema. To be specific, (i) a
graph schema is introduced to bound the extraction agent that ensures the quality and conciseness with
targeted entity types, relations and attribute types; The seed schema is continuously and automatically
expanded based on the feedback. (ii) To obtain higher-level knowledge upon the schema, we develop dually-
perceived community detection, fusing structural topology with subgraph semantics for comprehensive
knowledge clustering. This naturally yields a hierarchical knowledge tree that supports both top-down
filtering and bottom-up reasoning with community summaries; (iii) An agentic retriever is designed to
interpret the same graph schema to transform complex queries into parallel sub-queries and perform iterative
reflection. The agent iteratively performs both reasoning and reflection for more advanced performance;
(iv) To alleviate the knowledge leaking problem in pre-trained LLM, we first propose a tailored anonymous
dataset with an â€˜Anonymity Reversionâ€™ task. Extensive experiments across six challenging benchmarks
demonstrate the robustness of Youtu-GraphRAG, remarkably moving the Pareto frontier with up to 90.71%
saving of token consumption and 16.62% higher accuracy over SOTA baselines. The results also indicate our
remarkable adaptability which allows seamless domain transfer with minimal intervention on the graph
schema, providing insights of the next evolutionary GraphRAG paradigm for real-world applications.
Contributions. In general, our primary contributions are summarized hereunder:
â€¢ We first propose a vertically unified Agentic GraphRAG framework to integrate graph construction and
retrieval for more robust and advanced reasoning, where both construction and retrieval agents are
bounded by graph schema for effective extraction and query decomposition, respectively;
â€¢ A novel theoretically-grounded community detection algorithm is employed to inject high-level sum-
2Youtu-GraphRAG
ExtractionAgent
KnowledgeTreeConstruction
 RetrievalAgent
Documents
Decomposition
UserQuery LLM
PlanningFour-LevelKnowledgeTree
ðŸ“¦GraphSchema/â”‚â”€ Entity typeâ”‚â”€ Relationâ”” Attribute Type
SeedGraphSchema
Figure 2. A toy overview of Youtu-GraphRAG that unifies graph construction and retrieval through a schema-guided
agentic paradigm. (i) An extraction agent automatically processes documents into structured knowledge via targeted
entity/relation extraction; (ii) A four-level knowledge tree is constructed upon the schema with a community detection
that fuses topological structures and graph semantics, enabling hierarchical reasoning;(iii) A retrieval agent decomposes
user queries into parallel sub-queries aligned with the schema, iteratively driving multi-route retrieval.
marization upon graph schema, simultaneously preserving structural and semantic graph properties;
â€¢ We present a tailored anonymous dataset and â€˜Anonymous Revertionâ€™ task is proposed to prevent LLM
knowledge leaking for fair evaluation of the GraphRAG performance;
â€¢ Extensive empirical experiments are conducted over five challenging benchmarks, showing state-of-the-art
performance across diverse reasoning tasks and domains that moves the Pareto frontier with up to 90.71%
saving of token costs and 16.62% higher accuracy.
2 Task Definition
In this section, we formally define the general GraphRAG pipeline with standardized notations from scratch,
including both graph construction and graph retrieval. We denote scalars as lowercase alphabets (e.g.,a),
vectors as boldface lowercase alphabets (e.g., a), matrices as boldface uppercase alphabets (e.g., A) and
copperplate for a set of elements (e.g., A). We refer to GraphRAG as the task of answering a natural language
question by first retrieving structured knowledge from a corpus and then generating a response.
Given a set of documentsD, GraphRAG first leverages a frozen LLMfLLM(Â·) to extract important knowledge,
connected by a structured graph G as output. To enrich the understanding of G, a community detection
algorithm fcomm(G) is employed to partition G into communities C = {C1, C2 . . .Cm} to obtain higher-level
summarizations. Based on the constructed graph G, given a complex query q âˆˆ Q, a retrieval model
fretrieve(q, G) = arg max P(Gsub | q) traverses the graph and retrieves top- k question-specific subgraphs
Gsub âŠ† Gthat maximize the similarity with given query q. The final performance is evaluated from multiple
aspects: (i) graph construction costs including time efficiency and token consumptions;(ii) retrieval accuracy
and efficiency; and (iii) final answer accuracy comparing apred and ground-truths agold.
2.1 Construction Stage
Beginning with the documents D as corpus, contemporary GraphRAG research includes two synergistic
knowledge organizations that form the graph G at different granularities. First, the fine-grained graph
Gtriple = (E, R, D) is constructed by using fLLM(D) to extract atomic units in the form of triples (h, r, t) from
each document d âˆˆ D, where entities {h, t} âˆˆ Eand relations r âˆˆ Rare explicitly linked to represent the
abundant relational information among them. The extraction is performed by the frozen LLM fLLM(d),
which processes raw text to populate Gtriple with schema-compliant triples. Concurrently in another pipeline
of research, a coarse-grained document graph Gdoc = (D, C) is built by directly clustering documents to
maximally preserve the raw context where the atomic units are documents instead of triples. To obtain
higher-level knowledge, a complementary community detection algorithm fcomm(G) is employed. Typically,
fcomm(G), including Louvain, Leiden, GMM [Traag et al., 2019, Sarthi et al., 2024], etc., operates over G with
3
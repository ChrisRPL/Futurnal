# 2509.17567v2.pdf

SII-GAIR
LIMI: Less is More for Agency
Yang Xiao*3,5 Mohan Jiang*1,2,5 Jie Sun*4,2,5 Keyu Li*1,2,5 Jifan Lin1,5 Yumin Zhuang1,5 Ji Zeng1,5
Shijie Xia1,2,5 Qishuo Hua1,5 Xuefeng Li1,2,5 Xiaojie Cai1,5 Tongyu Wang2 Yue Zhang2 Liming Liu2
Xia Wu2 Jinlong Hou2 Yuan Cheng2 Wenjie Li3 Xiang Wang4 Dequan Wang1,2 Pengfei Liu†1,2,5
1SJTU 2SII 3PolyU 4USTC 5GAIR
SII Open Source:
 AgencyBench
 SII CLI/githubCode
Models/da◎abaseDatasets
Abstract
We define “Agency” as the emergent capacity of AI systems to function as autonomous agents—actively
discovering problems, formulating hypotheses, and executing solutions through self-directed engagement
with environments and tools. This fundamental capability marks the dawn of the “Age of AI Agency”, driven
by a critical industry shift: the urgent need for AI systems thatdon’t just think, but work. While current AI
excels at reasoning and generating responses, industries demand autonomous agents that can execute tasks,
operate tools, and drive real-world outcomes. As agentic intelligence becomes the defining characteristic
separating cognitive systems from productive workers, efficiently cultivating machine autonomy becomes
paramount. Current approaches assume that more data yields better agency, following traditional scaling
laws from language modeling. We fundamentally challenge this paradigm.LIMI(Less Is More for
Intelligent Agency) demonstrates that agency follows radically different development principles. Through
strategic focus on collaborative software development and scientific research workflows, we show that
sophisticated agentic intelligence can emerge from minimal but strategically curated demonstrations of
autonomous behavior. Using only 78 carefully designed training samples, LIMI achieves 73.5% on
AgencyBench, dramatically outperforming state-of-the-art models: Kimi-K2-Instruct (24.1%), DeepSeek-
V3.1 (11.9%), Qwen3-235B-A22B-Instruct (27.5%), and GLM-4.5 (45.1%). Most strikingly, LIMI
demonstrates 53.7% improvement over models trained on 10,000 samples—achieving superior agentic
intelligence with 128 times fewer samples.
Our findings establish theAgency Efficiency Principle: machine autonomy emerges not from data abun-
dance but from strategic curation of high-quality agentic demonstrations. This discovery fundamentally
reshapes how we develop autonomous AI systems, suggesting thatmastering agency requires under-
standing its essence, not scaling training data. As industries transition from thinking AI to working AI,
LIMI provides a paradigm for sustainable cultivation of truly agentic intelligence.
Less Is More for Agency !
Ours: LIMI
AFM WebAgent DatasetCC-Bench 29.236.747.8
73.5
Samples11.91 3 98128
53.7%Gain 0.8% Samples
DeepSeek 3.1 Baseline
AFM CodeAgent Dataset
PerformancePerformance
11.9DS-3.1
24.1
Kimi-K2
27.5
Qwen-3
45.1
GLM-4.5
73.5
LIMI
Figure 1: LIMI demonstrates the Less-Is-More principle for agentic intelligence.Left:LIMI achieves 73.5%
performance on AgencyBench, outperforming all baseline models.Right:Using only 78 training samples, LIMI
shows 53.7% improvement over models trained on 10,000 samples.
* Equal contribution.
† Corresponding author.
1
arXiv:2509.17567v2  [cs.AI]  25 Sep 20251. Introduction
SII-GAIR
1 Introduction
The emergence of agentic Large Language Models (LLMs)–systems that can reason, act, and interact au-
tonomously (Locke, 1987)–represents a paradigm shift from passive AI assistants to proactive intelligent agents (Wang
et al., 2024; Xi et al., 2023). We defineAgencyas the emergent capacity of AI systems to function as autonomous
agents–actively discovering problems, formulating hypotheses, and executing solutions through self-directed
engagement with environments and tools. This fundamental capability marks the dawn of theAge of AI Agency,
driven by a critical industry shift: the urgent need for AI systems thatdon’t just think, but work. While current
AI excels at reasoning and generating responses (Brown et al., 2020; Chowdhery et al., 2023; Touvron et al., 2023;
OpenAI, 2023; Anil et al., 2023), industries demand autonomous agents that can execute tasks, operate tools, and
drive real-world outcomes through capabilities like autonomous task execution (Qin et al., 2023; Yang et al., 2023;
Parisi et al., 2022), multi-step reasoning (Wei et al., 2022; Yao et al., 2024b; Besta et al., 2024; Zhang et al., 2023b;
Dhuliawala et al., 2023), and collaborative problem-solving (Li et al., 2023; Chan et al., 2023; Du et al., 2023;
Zhang et al., 2023a; Qian et al., 2023).
However, the development of such agentic systems faces critical challenges. Current approaches assume that
more data yields better agentic intelligence, following traditional scaling laws from language modeling (Kaplan
et al., 2020; Rae et al., 2021; Chowdhery et al., 2023; Scao et al., 2022; Zhang et al., 2022). This paradigm leads to
increasingly complex training pipelines and substantial resource requirements, yet this fundamental assumption
remains largely untested:do agentic capabilities truly require exposure to vast amounts of training data, or could
they emerge more efficiently through strategic approaches?Emerging evidence from adjacent domains suggests a
compelling alternative paradigm. LIMA (Zhou et al., 2023) achieved effective model alignment with only 1,000
carefully curated examples, while LIMO (Ye et al., 2025) demonstrated that complex mathematical reasoning can
emerge from just 817 strategically selected training samples, achieving a remarkable 45.8% absolute improvement
with only 1% of the data typically required. These convergent findings suggest that strategic data curation may be
fundamentally more powerful than dataset scale for developing sophisticated AI capabilities, naturally leading us to
investigate whether agentic intelligence follows similar efficiency principles.
We introduceLIMI(LessIsMore forIntelligentAgency), which demonstrates that agency follows radically
different development principles from traditional scaling approaches. Through strategic focus on collaborative
software development and scientific research workflows–domains that collectively span the majority of knowledge
work scenarios–we show that sophisticated agentic intelligence can emerge from minimal but strategically curated
demonstrations of autonomous behavior. Our approach is grounded in three core innovations: (i) First, we pioneer
novel agentic user query synthesis methodologies, including human-AI collaborative query collection from real-
world scenarios and systematic GitHub pull request-based query synthesis using advanced LLMs, ensuring that
our training demonstrations capture authentic patterns of agentic behavior while maintaining ecological validity;
(ii) Second, we develop a systematic trajectory collection protocol that captures complete multi-turn interaction
sequences for each curated query, recording the full collaborative workflow from initial task understanding through
iterative model reasoning, tool utilization, and environmental feedback to successful task completion, providing
high-quality training demonstrations of sophisticated agentic behavior in realistic operational contexts; (iii) Third,
we reveal the data efficiency principle for AI agency cultivation, demonstrating that sophisticated agentic intelligence
emerges from strategic curation of minimal high-quality demonstrations rather than large-scale data accumulation,
fundamentally challenging traditional scaling paradigms in agentic AI development.
Using only 78 carefully designed training samples, LIMI achieves 73.5% on comprehensive agency benchmarks,
dramatically outperforming state-of-the-art models: Kimi-K2-Instruct (24.1%), DeepSeek-V3.1 (11.9%), Qwen3-
235B-A22B-Instruct (27.5%), and GLM-4.5 (45.1%). Most strikingly, LIMI demonstrates 53.7% improvement
over models trained on 10,000 samples–achieving superior agentic intelligence with 128 times fewer samples.
These findings establish theAgency Efficiency Principle: machine autonomy emerges not from data abundance but
from strategic curation of high-quality agentic demonstrations. This discovery fundamentally reshapes how we
develop autonomous AI systems, suggesting that mastering agency requires understanding its essence, not scaling
training data. As industries transition from thinking AI to working AI, LIMI provides a paradigm for sustainable
cultivation of truly agentic intelligence, demonstrating that the key to effective agentic AI development lies in
strategic data curation rather than computational scale.
2 Preliminary
The transition from passive AI assistants to autonomous intelligent agents represents a fundamental paradigm
shift that requires precise definition of both the cognitive capabilities and operational contexts that constitute
genuine agency. As established in our framework,Agencyrepresents the emergent capacity of AI systems to
function as autonomous agents—actively discovering problems, formulating hypotheses, and executing solutions
through self-directed engagement with environments and tools. This paradigm shift demands AI systems that don’t
22.1 Long-Horizon Tasks and Agentic Complexity
SII-GAIR
User Query Example: Gomoku Battle -From Basics to Expert AISubtask1:WebFrontendDevelopment(UI/Rendering)Goal:Implementa15×15boardrendering,blackandwhitealternatemoves(nowindetectionyet).Constraints:OnlynativeHTML/CSS/JS;nothird-partylibraries.Boardsupportsclick-to-place,disallowingstonesonoccupiedpoints.Providea”Reset”button.Deliverables:Files:index.html,styles.css,app.js.Boardasequal-spacedgrid(CanvasorDOM).AcceptanceCriteria:Blackmovesfirst.Eachvalidclickplacesastoneonthenearestintersection.Noduplicatemovesonthesameintersection.Afterreset,boardclearsandblackstartsagain.
Subtask3:StateManagement(Undo/Redo/Replay)Goal:Supportlocaltwo-playergamemanagement:movehistory,undo/redo,andstep-by-stepreplay.Constraints:Maintainmoves[]stack,eachelementincludescoordinatesandcolor.Undoallowsbranching(historytruncates).Aftergameends,replayandrestartstillavailable.Deliverables:Buttons:Undo,Redo,Replay(morethan300mspermove).Boardedgesshowcoordinates(A–O/1–15).AcceptanceCriteria:Undobacktoopeningwithouterror.Redoreturnstolateststep.Duringreplay,nomanualmovesallowed.Afterreplayends,normalplayresumes.Undoingpastwinningmoveunlocksboard.
Subtask4:SimpleRule-Based/HeuristicAIGoal:AddHumanvsAImodewithsimpleAI.Easy:Randomlegalmoves,prefercentral7×7.Medium:Ifwinningin1move→takeit.Elseblockopponent’sopenfour.Elseusescoring(openthree>blockedthree>opentwo).Constraints:Modeselection:LocalPvP/HumanvsAI(choosewhomovesfirst).AImustdecidewithin100msonempty15×15board.Deliverables:Dropdownformodeandfirstplayer.Statusbar:”AIThinking...”.AIfunction:aiMove(level);scoringfunctionmodularized.AcceptanceCriteria:MediumAIblockshuman’s”openfour”.MediumAItakesimmediatewinningmove.EasyAIsignificantlyweaker(Mediummorethan70percentwinrateoverEasy).
Subtask5:AdvancedAI(SearchAlgorithms,e.g.,Minimax)Goal:ImplementstrongerAIdifficultywithperformancecontrol.Hard:Minimax+Alpha-Beta,fixeddepth(2–3ply),candidatepruning(recentmoves,topKscoring).Expert:BasedonHard,additerativedeepening,timeslicing(e.g.500mscutoff),transpositiontable(hashcaching),killermoveheuristic.Constraints:Provideunifiedtime/nodecountmetricsinUI(e.g.”depthd=3,nodesn=12,345,time=0.43s”).Searchmustobeytimelimit;returnbestevaluationsofar.Deliverables:Difficulty:Easy/Medium/Hard/Expert;selectablefirstplayer.Debugpanel(collapsible):evalscore,candidatelist(topK),searchstats.Clearfunctionlayers:evaluate(board,player),generateCandidates(board),search(root,timeLimit).AcceptanceCriteria:Hard/Expertprioritizedefenseagainst”openfour”and”doublethreats”.ExpertexpandsmorenodesthanHardwithin500msandachieveshigherwinrate.Ontypicalattack/defensetestcases,Expertmatchesorapproximatesreferencesolutions.
Subtask2:AdvancedDataFiltering&SortingGoal:OntopofTask1,adddetectionoffiveinarow(horizontal,vertical,bothdiagonals).Highlightwinningsequenceandlockboard.Constraints:Aftervictory,forbidfurthermoves;”Reset”startsanewgame.DetectionalgorithmshouldbeO(1)incrementalneighborhoodcheckorO(n)range(nofullscan).Deliverables:Highlight5winningstoneswithlineorglow.Display”Black/WhiteWins”atpagetop.Detectioncodeinstandalonefunction:checkWin(lastMove).AcceptanceCriteria:Immediatewinwhen5inarowisformed.Sixormoreinarowstillcountsaswin(standardGomokurule).Edge-of-boardwinsaredetectedcorrectly.Clickingoccupiedorlockedboardisinvalid.
Figure 2: An example of the user query, illustrating how a single query encompasses multiple interconnected
subtasks across planning, execution, and collaboration dimensions, demonstrating the density of learning signals in
high-quality demonstrations.
just think, but work, requiring sophisticated integration of autonomous task execution, multi-step reasoning, and
collaborative problem-solving capabilities.
2.1 Long-Horizon Tasks and Agentic Complexity
The development of agentic intelligence is fundamentally tested through complex, multi-step challenges that require
sustained cognitive effort and strategic coordination across extended interaction sequences. As illustrated in Figure
2, these scenarios demand sophisticated integration of capabilities including autonomous task execution, multi-step
reasoning, and collaborative problem-solving across diverse domains like software development and scientific
research.
Such tasks exhibit temporal complexity through multi-round interactions requiring coherent state tracking
and cumulative reasoning. They demand strategic planning capabilities that decompose complex objectives into
manageable sub-goals while adapting strategies based on environmental feedback. Tool orchestration becomes
essential as real-world agentic tasks require coordinated use of multiple systems with integrated result processing.
Collaborative communication ensures effective human-AI coordination throughout extended problem-solving
processes, distinguishing agentic intelligence from passive AI systems that merely respond to individual queries.
2.2 Domain Specification: Vibe Coding and Research Workflows
To validate our approach, we focus on two fundamental domains that collectively span the majority of knowledge
work scenarios and require the full spectrum of agentic capabilities.
Vibe CodingVibe coding represents collaborative software development where LLMs or agents work alongside
human developers in natural, context-rich environments. This domain demands code understanding and generation
across existing codebases, development environment navigation through complex tool ecosystems, iterative problem
solving through debugging and optimization cycles, and collaborative communication for technical coordination.
The complexity lies in a holistic understanding of development contexts and principled decision-making under
evolving requirements.
Research WorkflowsResearch workflows encompass scenarios where agents navigate complex scientific pro-
cesses, including literature search, data analysis, experiment design, and insight generation. These workflows
3
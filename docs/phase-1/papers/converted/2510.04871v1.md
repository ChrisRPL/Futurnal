# 2510.04871v1.pdf

Less is More: Recursive Reasoning with Tiny Networks
Alexia Jolicoeur-Martineau
Samsung SAIL Montr´eal
alexia.j@samsung.com
Abstract
Hierarchical Reasoning Model (HRM) is a
novel approach using two small neural net-
works recursing at different frequencies. This
biologically inspired method beats Large Lan-
guage models (LLMs) on hard puzzle tasks
such as Sudoku, Maze, and ARC-AGI while
trained with small models (27M parameters)
on small data (∼ 1000 examples). HRM holds
great promise for solving hard problems with
small networks, but it is not yet well un-
derstood and may be suboptimal. We pro-
pose Tiny Recursive Model (TRM), a much
simpler recursive reasoning approach that
achieves significantly higher generalization
than HRM, while using a single tiny network
with only 2 layers. With only 7M parameters,
TRM obtains 45% test-accuracy on ARC-AGI-
1 and 8% on ARC-AGI-2, higher than most
LLMs (e.g., Deepseek R1, o3-mini, Gemini 2.5
Pro) with less than 0.01% of the parameters.
1. Introduction
While powerful, Large Language models (LLMs) can
struggle on hard question-answer problems. Given
that they generate their answer auto-regressively, there
is a high risk of error since a single incorrect token can
render an answer invalid. To improve their reliabil-
ity, LLMs rely on Chain-of-thoughts (CoT) (Wei et al.,
2022) and Test-Time Compute (TTC) (Snell et al., 2024).
CoTs seek to emulate human reasoning by having the
LLM to sample step-by-step reasoning traces prior to
giving their answer. Doing so can improve accuracy,
but CoT is expensive, requires high-quality reasoning
data (which may not be available), and can be brittle
since the generated reasoning may be wrong. To fur-
ther improve reliability, test-time compute can be used
by reporting the most common answer out of K or the
highest-reward answer (Snell et al., 2024).
Figure 1.Tiny Recursion Model (TRM) recursively improves
its predicted answer y with a tiny network. It starts with the
embedded input question x and initial embedded answer
y, and latent z. For up to Nsup = 16 improvements steps,
it tries to improve its answer y. It does so by i) recursively
updating n times its latent z given the question x, current
answer y, and current latent z (recursive reasoning), and
then ii) updating its answer y given the current answer y
and current latent z. This recursive process allows the model
to progressively improve its answer (potentially address-
ing any errors from its previous answer) in an extremely
parameter-efficient manner while minimizing overfitting.
1
arXiv:2510.04871v1  [cs.LG]  6 Oct 2025Recursive Reasoning with Tiny Networks
However, this may not be enough. LLMs with CoT
and TTC are not enough to beat every problem. While
LLMs have made significant progress on ARC-AGI
(Chollet, 2019) since 2019, human-level accuracy still
has not been reached (6 years later, as of writing of
this paper). Furthermore, LLMs struggle on the newer
ARC-AGI-2 (e.g., Gemini 2.5 Pro only obtains 4.9% test
accuracy with a high amount of TTC) (Chollet et al.,
2025; ARC Prize Foundation, 2025b).
An alternative direction has recently been proposed by
Wang et al. (2025). They propose a new way forward
through their novel Hierarchical Reasoning Model
(HRM), which obtains high accuracy on puzzle tasks
where LLMs struggle to make a dent (e.g., Sudoku
solving, Maze pathfinding, and ARC-AGI). HRM is a
supervised learning model with two main novelties: 1)
recursive hierarchical reasoning, and 2)deep supervision.
Recursive hierarchical reasoningconsists of recurs-
ing multiple times through two small networks (fL at
high frequency and fH at low frequency) to predict the
answer. Each network generates a different latent fea-
ture: fL outputs zH and fH outputs zL. Both features
(zL, zH) are used as input to the two networks. The
authors provide some biological arguments in favor of
recursing at different hierarchies based on the different
temporal frequencies at which the brains operate and
hierarchical processing of sensory inputs.
Deep supervisionconsists of improving the answer
through multiple supervision steps while carrying the
two latent features as initialization for the improve-
ment steps (after detaching them from the computa-
tional graph so that their gradients do not propagate).
This provide residual connections, which emulates
very deep neural networks that are too memory ex-
pensive to apply in one forward pass.
An independent analysis on the ARC-AGI benchmark
showed that deep supervision seems to be the primary
driver of the performance gains (ARC Prize Founda-
tion, 2025a). Usingdeep supervisiondoubled accuracy
over single-step supervision (going from 19% to 39%
accuracy), whilerecursive hierarchical reasoningonly
slightly improved accuracy over a regular model with
a single forward pass (going from 35.7% to 39.0% ac-
curacy). This suggests that reasoning across different
supervision steps is worth it, but the recursion done
in each supervision step is not particularly important.
In this work, we show that the benefit fromrecursive
reasoningcan be massively improved, making it much
more than incremental. We propose Tiny Recursive
Model (TRM), an improved and simplified approach
using a much smaller tiny network with only 2 lay-
ers that achieves significantly higher generalization
than HRM on a variety of problems. In doing so, we
improve the state-of-the-art test accuracy on Sudoku-
Extreme from 55% to 87%, Maze-Hard from 75% to
85%, ARC-AGI-1 from 40% to 45%, and ARC-AGI-2
from 5% to 8%.
2. Background
HRM is described in Algorithm 2. We discuss the
details of the algorithm further below.
2.1. Structure and goal
The focus of HRM is supervised learning. Given an
input, produce an output. Both input and output are
assumed to have shape [B, L] (when the shape differs,
padding tokens can be added), where B is the batch-
size andLis the context-length.
HRM contains four learnable components: the in-
put embedding fI (·; θI ), low-level recurrent network
fL(·; θL), high-level recurrent network fH(·; θH), and
the output head fO(·; θO). Once the input is embedded,
the shape becomes [B, L, D] where D is the embedding
size. Each network is a 4-layer Transformers architec-
ture (Vaswani et al., 2017), with RMSNorm (Zhang
& Sennrich, 2019), no bias (Chowdhery et al., 2023),
rotary embeddings (Su et al., 2024), and SwiGLU acti-
vation function (Hendrycks & Gimpel, 2016; Shazeer,
2020).
2.2. Recursion at two different frequencies
Given the hyperparameters used by Wang et al. (2025)
(n= 2 fL steps, 1 fH steps; done T= 2 times), a
forward pass of HRM is done as follows:
x←f I ( ˜x)
zL ←f L (zL +z H +x ) # without gradients
zL ←f L (zL +z H +x ) # without gradients
zH ←f H (zL +z H) # without gradients
zL ←f L (zL +z H +x ) # without gradients
zL ←z L.detach()
zH ←z H.detach()
zL ←f L (zL +z H +x ) # with gradients
zH ←f H (zL +z H) # with gradients
ˆy←argmax(f O (zH))
where ˆy is the predicted output answer, zL and zH are
either initialized embeddings or the embeddings of
the previous deep supervision step (after detaching
them from the computational graph). As can be seen,
2Recursive Reasoning with Tiny Networks
def hrm(z, x, n=2, T=2): # hierarchical reasoning
zH, zL = z
with torch.no grad():
for i in range(nT−2):
zL = L net(zL, zH, x)
if (i + 1) % T == 0:
zH = H net(zH, zL)
# 1−step grad
zL = L net(zL, zH, x)
zH = H net(zH, zL)
return (zH, zL), output head(zH), Q head(zH)
def ACT halt(q, y hat, y true):
target halt = (y hat == y true)
loss = 0.5∗binary cross entropy(q[0], target halt)
return loss
def ACT continue(q, last step):
if last step:
target continue = sigmoid(q[0])
else:
target continue = sigmoid(max(q[0], q[1])))
loss = 0.5∗binary cross entropy(q[1], target continue)
return loss
# Deep Supervision
for x input, y true in train dataloader:
z = z init
for step in range(N sup): # deep supervision
x = input embedding(x input)
z, y pred, q = hrm(z, x)
loss = softmax cross entropy(y pred, y true)
# Adaptive computational time (ACT) using Q−learning
loss += ACT halt(q, y pred, y true)
, , q next = hrm(z, x) # extra forward pass
loss += ACT continue(q next, step == N sup−1)
z = z.detach()
loss.backward()
opt.step()
opt.zero grad()
if q[0]>q[1]: # early−stopping
break
Figure 2.Pseudocode of Hierarchical Reasoning Models
(HRMs).
a forward pass of HRM consists of applying 6 function
evaluations, where the first 4 function evaluations are
detached from the computational graph and are not
back-propagated through. The authors uses n= 2
with T= 2 in all experiments, but HRM can be gener-
alized by allowing for an arbitrary number of L steps
(n) and recursions (T) as shown in Algorithm 2.
2.3. Fixed-point recursion with 1-step gradient
approximation
Assuming that (zL, zH) reaches a fixed-point (z∗
L, z∗
H)
through recursing from bothf L andf H,
z∗
L ≈f L (z∗
L +z H +x )
z∗
H ≈f H (zL +z ∗
H) ,
the Implicit Function Theorem (Krantz & Parks, 2002)
with the 1-step gradient approximation (Bai et al.,
2019) is used to approximate the gradient by back-
propagating only the last fL and fH steps. This theo-
rem is used to justify only tracking the gradients of
the last two steps (out of 6), which greatly reduces
memory demands.
2.4. Deep supervision
To improve effective depth, deep supervision is used.
This consists of reusing the previous latent features
(zH and zL) as initialization for the next forward pass.
This allows the model to reason over many iterations
and improve its latent features ( zL and zH) until it
(hopefully) converges to the correct solution. At most
Nsup =16 supervision steps are used.
2.5. Adaptive computational time (ACT)
With deep supervision, each mini-batch of data sam-
ples must be used for Nsup = 16 supervision steps
before moving to the next mini-batch. This is expen-
sive, and there is a balance to be reached between
optimizing a few data examples for many supervision
steps versus optimizing many data examples with less
supervision steps. To reach a better balance, a halting
mechanism is incorporated to determine whether the
model should terminate early. It is learned through
a Q-learning objective that requires passing the zH
through an additional head and running an additional
forward pass (to determine if halting now rather than
later would have been preferable). They call this
method Adaptive computational time (ACT). It is only
used during training, while the full Nsup = 16 super-
vision steps are done at test time to maximize down-
stream performance. ACT greatly diminishes the time
spent per example (on average spending less than 2
steps on the Sudoku-Extreme dataset rather than the
full Nsup = 16 steps), allowing more coverage of the
dataset given a fixed number of training iterations.
2.6. Deep supervision and 1-step gradient
approximations replaces BPTT
Deep supervision and the 1-step gradient approxima-
tion provide a more biologically plausible and less
computationally-expansive alternative to Backpropa-
gation Through Time (BPTT) (Werbos, 1974; Rumel-
hart et al., 1985; LeCun, 1985) for solving the temporal
credit assignment (TCA) (Rumelhart et al., 1985; Wer-
bos, 1988; Elman, 1990) problem (Lillicrap & Santoro,
2019). The implication is that HRM can learn what
would normally require an extremely large network
without having to back-propagate through its entire
depth. Given the hyperparameters used by Jang et al.
(2023) in all their experiments, HRM effectively rea-
sons over nlayers (n+ 1)TNsup = 4 ∗( 2 + 1)∗ 2 ∗ 16 =
384 layers of effective depth.
3